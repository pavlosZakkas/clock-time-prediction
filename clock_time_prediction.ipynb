{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A2_tell_the_time.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bXaic0jdMCRn",
        "jN3FRzZQMIyd",
        "w07TRQoYPpx4",
        "oJtnk24wMZtE",
        "U4LwMe4IMhFo"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icJ4dTQzLq_J"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltJz7mx3LlZs",
        "outputId": "1c30f6d7-5cee-4579-9e1b-a6bbb0811638"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, Rescaling, Input\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.losses import Loss, CosineSimilarity\n",
        "from dataclasses import dataclass\n",
        "from keras import backend as K\n",
        "from sklearn.utils import shuffle\n",
        "import math\n",
        "from functools import partial\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import classification_report, mean_absolute_error\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "np.set_printoptions(threshold=sys.maxsize)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-ePBxXtL0Er"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk-LumFaOr19"
      },
      "source": [
        "TRAIN_SET_RATE = 0.65\n",
        "VALID_SET_RATE = 0.15\n",
        "TEST_SET_RATE = 0.20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lEvs4_OQX40"
      },
      "source": [
        "@dataclass\n",
        "class Dataset():\n",
        "  name: str\n",
        "  input_shape: object\n",
        "  x_train: object\n",
        "  y_train: object\n",
        "  x_valid: object\n",
        "  y_valid: object\n",
        "  x_test: object\n",
        "  y_test: object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVZ7sLiILs3r"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4w58tasXOUJa",
        "outputId": "5a7d4024-4b91-4d3f-cde5-2037ccf9f534"
      },
      "source": [
        "x = np.load('data/images.npy')\n",
        "y = np.load('data/labels.npy')\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18000, 150, 150)\n",
            "(18000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwmKlEZPLvs8"
      },
      "source": [
        "## Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOh8w7hrOqBX",
        "outputId": "2451f9c9-a5a1-4d80-bbe0-37b50a5eb2fe"
      },
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "  x = x.reshape(x.shape[0], 1, x.shape[1], x.shape[2])\n",
        "  input_shape = (1, x.shape[1], x.shape[2])\n",
        "else:\n",
        "  x = x.reshape(x.shape[0], x.shape[1], x.shape[2], 1)\n",
        "  input_shape = (x.shape[1], x.shape[2], 1)\n",
        "\n",
        "x = x.astype('float32')\n",
        "x, y = shuffle(x, y, random_state=42)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=TEST_SET_RATE, random_state=42)\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=VALID_SET_RATE, random_state=42)\n",
        "\n",
        "print(f'Input shape: {input_shape}')\n",
        "print(f'Train set shape: {x_train.shape}')\n",
        "print(f'Validation set shape: {x_valid.shape}')\n",
        "print(f'Test set shape: {x_test.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (150, 150, 1)\n",
            "Train set shape: (12240, 150, 150, 1)\n",
            "Validation set shape: (2160, 150, 150, 1)\n",
            "Test set shape: (3600, 150, 150, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNXtWO0hMNeO"
      },
      "source": [
        "## Output transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNdjaRYAPUIt"
      },
      "source": [
        "def decimal_representation_of(y):\n",
        "  return y[:,0] + y[:,1] / 60\n",
        "\n",
        "def cyclical_representation_of(y):\n",
        "  decimal_y = decimal_representation_of(y)\n",
        "  return np.array([np.sin(2*np.pi*decimal_y/12), np.cos(2*np.pi*decimal_y/12)])\n",
        "\n",
        "def cyclical_representation_of_hours(hours):\n",
        "  return np.array([np.sin(2*np.pi*hours/12), np.cos(2*np.pi*hours/12)])\n",
        "\n",
        "def cyclical_representation_of_minutes(minutes):\n",
        "  return np.array([np.sin(2*np.pi*minutes/60), np.cos(2*np.pi*minutes/60)])\n",
        "\n",
        "\n",
        "def represented_in_range(number, interval_in_minutes):\n",
        "  return [\n",
        "          1 if number >= i and number < i + interval_in_minutes/60 else 0\n",
        "          for i in np.arange(0, 12, interval_in_minutes / 60)\n",
        "          ]\n",
        "\n",
        "def grouped_in_classes(y, interval_in_minutes=30):\n",
        "  decimal_y = decimal_representation_of(y)\n",
        "  return np.array(\n",
        "      [\n",
        "       represented_in_range(yi, interval_in_minutes) \n",
        "       for yi in decimal_y\n",
        "      ])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4kpV0ODL3ko"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTEp4QB8OWlf"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 50\n",
        "PATIENCE_IN_EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jh5urBiL64B"
      },
      "source": [
        "## Custom loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_OTqKtiPXwg"
      },
      "source": [
        "class DecimalTimesMeanLoss(Loss):\n",
        "\n",
        "  def call(self, y_true, y_pred):\n",
        "    return tf.reduce_mean(\n",
        "      tf.math.minimum(\n",
        "          tf.math.abs(y_true - y_pred),\n",
        "          tf.math.abs(tf.math.minimum(y_true, y_pred) + 12 - tf.math.maximum(y_true, y_pred))\n",
        "          )\n",
        "      )\n",
        "    \n",
        "class MinutesMeanLoss(Loss):\n",
        "\n",
        "  def call(self, y_true, y_pred):\n",
        "    return tf.reduce_mean(\n",
        "      tf.math.minimum(\n",
        "          tf.math.abs(y_true - y_pred),\n",
        "          tf.math.abs(tf.math.minimum(y_true, y_pred) + 60 - tf.math.maximum(y_true, y_pred))\n",
        "          )\n",
        "      )\n",
        "\n",
        "class CyclicalTimesDistanceMeanLoss(Loss):\n",
        "\n",
        "  def call(self, y_true, y_pred):\n",
        "    loss = tf.reduce_mean(\n",
        "        tf.math.sqrt(tf.reduce_sum(\n",
        "            tf.math.square(y_true - y_pred), \n",
        "            axis=1\n",
        "            ))\n",
        "        )\n",
        "    return loss\n",
        "\n",
        "class CyclicalTimesMinutesMeanLoss(Loss):\n",
        "\n",
        "  def call(self, y_true, y_pred):\n",
        "\n",
        "    dot_product = tf.reduce_sum(tf.multiply(y_pred, y_true), axis=1)\n",
        "    y_pred_norm = tf.norm(y_pred, axis=1)\n",
        "    y_true_norm = tf.norm(y_true, axis=1)\n",
        "    multiplied_norms = tf.multiply(y_pred_norm, y_true_norm)\n",
        "\n",
        "    arccos = tf.math.acos(dot_product / multiplied_norms)\n",
        "    arccos = tf.where(tf.math.is_nan(arccos), tf.zeros_like(arccos), arccos)\n",
        "\n",
        "    return 60 * (arccos / (2*np.pi) )\n",
        "\n",
        "class DecimalTimesCosineSimilarityLoss(Loss):\n",
        "\n",
        "  def call(self, y_true, y_pred):\n",
        "    y_cyclical_true = tf.map_fn(lambda x: [tf.math.sin(2* np.pi * x / 12), tf.math.cos(2* np.pi * x / 12)], y_true, dtype=[tf.float32, tf.float32])\n",
        "    y_cyclical_pred = tf.map_fn(lambda x: [tf.math.sin(2* np.pi * x / 12), tf.math.cos(2* np.pi * x / 12)], y_pred, dtype=[tf.float32, tf.float32])\n",
        "\n",
        "    cosine_loss = CosineSimilarity(axis=1)\n",
        "    return cosine_loss(y_cyclical_true, y_cyclical_pred)\n",
        "\n",
        "\n",
        "def adjusted_mae_numpy(a, b, max_value):\n",
        "        \n",
        "    return np.average(np.min(np.concatenate((np.abs(a - b), np.abs(np.min(np.concatenate((a, b), axis=1), axis=1) + max_value - np.max(np.concatenate((a, b), axis=1), axis=1)).reshape(-1, 1)), axis=1), axis=1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urly9Y_7L-3d"
      },
      "source": [
        "## Regression CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cpZ9ntoQTgm"
      },
      "source": [
        "def mean_minutes_loss_for_cyclical_time(y_true, y_pred):\n",
        "  y_pred_unit_vectors = tf.map_fn(lambda x: x / tf.norm(x), y_pred)\n",
        "  y_true_unit_vectors = tf.map_fn(lambda x: x / tf.norm(x), y_true)\n",
        "  print(y_pred_unit_vectors)\n",
        "  print(y_true_unit_vectors)\n",
        "  minutes_losses = tf.map_fn(\n",
        "      lambda i: \n",
        "      60 * 12 * tf.acos(tf.tensordot(y_pred_unit_vectors[i], y_true_unit_vectors[i], 1)) / (2 * tf.constant(np.pi)) , \n",
        "      tf.range(y_pred_unit_vectors.shape[0])\n",
        "      )\n",
        "  return tf.reduce_mean(minutes_losses)\n",
        "  \n",
        "def mean_minutes_loss_metric(y_true, y_pred):\n",
        "    return tf.reduce_mean(\n",
        "      tf.math.minimum(\n",
        "          tf.math.abs(y_true - y_pred),\n",
        "          tf.math.abs(tf.math.minimum(y_true, y_pred) + 12 - tf.math.maximum(y_true, y_pred))\n",
        "          )\n",
        "      ) * 60\n",
        "    \n",
        "def regression_cnn_1(loss, dataset, output_units, metric=None):\n",
        "  DefaultConv2D = partial(Conv2D,kernel_size=3, activation='leaky_relu', padding=\"VALID\")\n",
        "\n",
        "  model = keras.models.Sequential([\n",
        "    Rescaling(1./255, input_shape=dataset.input_shape),\n",
        "    DefaultConv2D(filters=16, kernel_size=5),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    DefaultConv2D(filters=32),\n",
        "    DefaultConv2D(filters=32),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    DefaultConv2D(filters=64),\n",
        "    DefaultConv2D(filters=64),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Dropout(0.4),\n",
        "    Flatten(),\n",
        "    \n",
        "    Dense(units=512, activation='elu', kernel_initializer='he_normal'),\n",
        "    Dense(units=512, activation='elu', kernel_initializer='he_normal'),\n",
        "    Dense(units=output_units, activation='linear'),\n",
        "  ])\n",
        "\n",
        "  if metric != None:\n",
        "    model.compile(optimizer='adam', loss=loss, metrics=[metric])\n",
        "  else:\n",
        "    model.compile(optimizer='adam', loss=loss)\n",
        "\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXaic0jdMCRn"
      },
      "source": [
        "## Classification CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka6cdi1JJwtX"
      },
      "source": [
        "def classification_cnn(dataset, classes, loss='categorical_crossentropy'):\n",
        "  tf.random.set_seed(42)\n",
        "  DefaultConv2D = partial(Conv2D,kernel_size=3, activation='leaky_relu', kernel_initializer='he_normal')\n",
        "\n",
        "  model = keras.models.Sequential([\n",
        "    Rescaling(1./255, input_shape=dataset.input_shape),\n",
        "    DefaultConv2D(filters=16, kernel_size=5),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    DefaultConv2D(filters=32),\n",
        "    DefaultConv2D(filters=32),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    DefaultConv2D(filters=64),\n",
        "    DefaultConv2D(filters=64),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(units=64, activation='leaky_relu', kernel_initializer='he_normal'),\n",
        "    Dense(units=64, activation='leaky_relu', kernel_initializer='he_normal'),\n",
        "    # Dense(units=1024, activation='relu'),\n",
        "    # Dropout(0.2),\n",
        "    # Dense(units=512, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
        "    # Dense(units=512, activation='relu'),\n",
        "    # Dropout(0.2),\n",
        "    Dense(units=classes, activation='softmax'),\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "      optimizer='adam',\n",
        "      loss=loss,\n",
        "      metrics=['accuracy'],\n",
        "      )\n",
        "  \n",
        "  model.summary()\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id8JF0MZQuJn"
      },
      "source": [
        "## Fitting a given model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpYqwEthSer6"
      },
      "source": [
        "def train(model, dataset):\n",
        "  model.fit(\n",
        "    dataset.x_train,\n",
        "    dataset.y_train,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=(dataset.x_valid, dataset.y_valid),\n",
        "    callbacks=[keras.callbacks.EarlyStopping(patience=PATIENCE_IN_EPOCHS)],\n",
        "  )\n",
        "\n",
        "def evaluate(model, x, y):\n",
        "  score = model.evaluate(x, y, verbose=0)\n",
        "  return score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF8300pKMFpH"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mOHmf1lMWIh"
      },
      "source": [
        "## Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN3FRzZQMIyd"
      },
      "source": [
        "#### Predict hours and minutes using decimal representation and MAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCOpRLaqS_vD",
        "outputId": "96954e5d-e46b-4d39-932f-13b63bea8a33"
      },
      "source": [
        "y_decimal_train = decimal_representation_of(y_train)\n",
        "y_decimal_valid = decimal_representation_of(y_valid)\n",
        "y_decimal_test = decimal_representation_of(y_test)\n",
        "\n",
        "dataset = Dataset(\n",
        "      name='decimal-representation',\n",
        "      input_shape=input_shape,\n",
        "      x_train=x_train,\n",
        "      y_train=y_decimal_train,\n",
        "      x_valid=x_valid,\n",
        "      y_valid=y_decimal_valid,\n",
        "      x_test=x_test,\n",
        "      y_test=y_decimal_test,\n",
        "  )\n",
        "\n",
        "decimal_hours_minutes_model = regression_cnn_1('mae', dataset, 1, mean_minutes_loss_metric)\n",
        "train(decimal_hours_minutes_model, dataset)\n",
        "print(f'Minutes loss on test set: {evaluate(decimal_hours_minutes_model, dataset.x_test, dataset.y_test)[1]}')\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_7 (Rescaling)     (None, 150, 150, 1)       0         \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 146, 146, 16)      416       \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 73, 73, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 71, 71, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 69, 69, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 34, 34, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 30, 30, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 15, 15, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 14400)             0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 512)               7373312   \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,706,209\n",
            "Trainable params: 7,706,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 45ms/step - loss: 3.1185 - mean_minutes_loss_metric: 180.1695 - val_loss: 3.0996 - val_mean_minutes_loss_metric: 185.0962\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 3.0138 - mean_minutes_loss_metric: 179.2668 - val_loss: 3.0769 - val_mean_minutes_loss_metric: 184.4748\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 2.9940 - mean_minutes_loss_metric: 179.0615 - val_loss: 3.0742 - val_mean_minutes_loss_metric: 184.3308\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 2.7462 - mean_minutes_loss_metric: 159.3924 - val_loss: 2.5447 - val_mean_minutes_loss_metric: 145.8173\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 2.4229 - mean_minutes_loss_metric: 139.4429 - val_loss: 2.3624 - val_mean_minutes_loss_metric: 134.3279\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 2.1549 - mean_minutes_loss_metric: 123.5170 - val_loss: 2.1033 - val_mean_minutes_loss_metric: 121.3669\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 1.8909 - mean_minutes_loss_metric: 107.0868 - val_loss: 1.7617 - val_mean_minutes_loss_metric: 100.9993\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 1.5689 - mean_minutes_loss_metric: 88.4624 - val_loss: 1.5091 - val_mean_minutes_loss_metric: 84.8554\n",
            "Epoch 9/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 1.2533 - mean_minutes_loss_metric: 70.8058 - val_loss: 1.1616 - val_mean_minutes_loss_metric: 64.6411\n",
            "Epoch 10/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 1.0507 - mean_minutes_loss_metric: 60.3666 - val_loss: 0.9935 - val_mean_minutes_loss_metric: 57.1490\n",
            "Epoch 11/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.8603 - mean_minutes_loss_metric: 50.2559 - val_loss: 0.9575 - val_mean_minutes_loss_metric: 55.5846\n",
            "Epoch 12/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.7345 - mean_minutes_loss_metric: 43.2759 - val_loss: 0.7358 - val_mean_minutes_loss_metric: 42.6590\n",
            "Epoch 13/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.6430 - mean_minutes_loss_metric: 38.1090 - val_loss: 0.7077 - val_mean_minutes_loss_metric: 41.0867\n",
            "Epoch 14/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.5669 - mean_minutes_loss_metric: 33.7110 - val_loss: 0.6389 - val_mean_minutes_loss_metric: 37.3325\n",
            "Epoch 15/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.5246 - mean_minutes_loss_metric: 31.3184 - val_loss: 0.6769 - val_mean_minutes_loss_metric: 38.8826\n",
            "Epoch 16/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.4927 - mean_minutes_loss_metric: 29.3445 - val_loss: 0.5923 - val_mean_minutes_loss_metric: 34.4251\n",
            "Epoch 17/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.4516 - mean_minutes_loss_metric: 26.9786 - val_loss: 0.5864 - val_mean_minutes_loss_metric: 34.2583\n",
            "Epoch 18/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.3941 - mean_minutes_loss_metric: 23.5218 - val_loss: 0.5142 - val_mean_minutes_loss_metric: 29.4407\n",
            "Epoch 19/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.3809 - mean_minutes_loss_metric: 22.7122 - val_loss: 0.4879 - val_mean_minutes_loss_metric: 28.2211\n",
            "Epoch 20/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.3451 - mean_minutes_loss_metric: 20.6013 - val_loss: 0.4876 - val_mean_minutes_loss_metric: 28.2488\n",
            "Epoch 21/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.3339 - mean_minutes_loss_metric: 19.9432 - val_loss: 0.5094 - val_mean_minutes_loss_metric: 28.9761\n",
            "Epoch 22/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.3176 - mean_minutes_loss_metric: 19.0031 - val_loss: 0.4669 - val_mean_minutes_loss_metric: 26.8710\n",
            "Epoch 23/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.3130 - mean_minutes_loss_metric: 18.7103 - val_loss: 0.4226 - val_mean_minutes_loss_metric: 24.2945\n",
            "Epoch 24/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.2690 - mean_minutes_loss_metric: 16.0684 - val_loss: 0.4155 - val_mean_minutes_loss_metric: 23.9214\n",
            "Epoch 25/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.2783 - mean_minutes_loss_metric: 16.6681 - val_loss: 0.4219 - val_mean_minutes_loss_metric: 24.2184\n",
            "Epoch 26/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.2733 - mean_minutes_loss_metric: 16.3228 - val_loss: 0.4415 - val_mean_minutes_loss_metric: 25.5144\n",
            "Epoch 27/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.2714 - mean_minutes_loss_metric: 16.2720 - val_loss: 0.4203 - val_mean_minutes_loss_metric: 23.8118\n",
            "Epoch 28/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.2534 - mean_minutes_loss_metric: 15.1827 - val_loss: 0.3928 - val_mean_minutes_loss_metric: 22.1138\n",
            "Epoch 29/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.2470 - mean_minutes_loss_metric: 14.7953 - val_loss: 0.4252 - val_mean_minutes_loss_metric: 24.6261\n",
            "Epoch 30/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.2382 - mean_minutes_loss_metric: 14.2786 - val_loss: 0.4036 - val_mean_minutes_loss_metric: 23.1720\n",
            "Epoch 31/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.2336 - mean_minutes_loss_metric: 13.9690 - val_loss: 0.3871 - val_mean_minutes_loss_metric: 22.0152\n",
            "Epoch 32/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.2398 - mean_minutes_loss_metric: 14.3680 - val_loss: 0.4074 - val_mean_minutes_loss_metric: 23.1983\n",
            "Epoch 33/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.2277 - mean_minutes_loss_metric: 13.6689 - val_loss: 0.3780 - val_mean_minutes_loss_metric: 21.5648\n",
            "Epoch 34/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.2149 - mean_minutes_loss_metric: 12.9005 - val_loss: 0.3758 - val_mean_minutes_loss_metric: 21.5231\n",
            "Epoch 35/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.2278 - mean_minutes_loss_metric: 13.6566 - val_loss: 0.3648 - val_mean_minutes_loss_metric: 20.7544\n",
            "Epoch 36/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2096 - mean_minutes_loss_metric: 12.5965 - val_loss: 0.3798 - val_mean_minutes_loss_metric: 21.7737\n",
            "Epoch 37/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.2139 - mean_minutes_loss_metric: 12.8380 - val_loss: 0.3605 - val_mean_minutes_loss_metric: 20.5450\n",
            "Epoch 38/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2048 - mean_minutes_loss_metric: 12.2701 - val_loss: 0.3560 - val_mean_minutes_loss_metric: 20.2786\n",
            "Epoch 39/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.2041 - mean_minutes_loss_metric: 12.2431 - val_loss: 0.3443 - val_mean_minutes_loss_metric: 19.5763\n",
            "Epoch 40/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.1927 - mean_minutes_loss_metric: 11.5623 - val_loss: 0.3555 - val_mean_minutes_loss_metric: 20.3967\n",
            "Epoch 41/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.2026 - mean_minutes_loss_metric: 12.1664 - val_loss: 0.3956 - val_mean_minutes_loss_metric: 22.7922\n",
            "Epoch 42/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.1995 - mean_minutes_loss_metric: 11.9663 - val_loss: 0.3638 - val_mean_minutes_loss_metric: 20.7764\n",
            "Epoch 43/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.1862 - mean_minutes_loss_metric: 11.1645 - val_loss: 0.3289 - val_mean_minutes_loss_metric: 18.7394\n",
            "Epoch 44/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.1866 - mean_minutes_loss_metric: 11.1926 - val_loss: 0.3345 - val_mean_minutes_loss_metric: 19.1284\n",
            "Epoch 45/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.1906 - mean_minutes_loss_metric: 11.4409 - val_loss: 0.3718 - val_mean_minutes_loss_metric: 21.2362\n",
            "Epoch 46/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.1872 - mean_minutes_loss_metric: 11.2300 - val_loss: 0.3419 - val_mean_minutes_loss_metric: 19.2632\n",
            "Epoch 47/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1740 - mean_minutes_loss_metric: 10.4413 - val_loss: 0.3291 - val_mean_minutes_loss_metric: 18.7151\n",
            "Epoch 48/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.1731 - mean_minutes_loss_metric: 10.3818 - val_loss: 0.3420 - val_mean_minutes_loss_metric: 19.4427\n",
            "Epoch 49/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.1768 - mean_minutes_loss_metric: 10.6033 - val_loss: 0.3594 - val_mean_minutes_loss_metric: 20.4950\n",
            "Epoch 50/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.1712 - mean_minutes_loss_metric: 10.2667 - val_loss: 0.3164 - val_mean_minutes_loss_metric: 18.0408\n",
            "Minutes loss on test set: 17.423974990844727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUXy79C3Qp5r"
      },
      "source": [
        "##### Observations\n",
        "Around 18 minutes loss on test set was observed when using decimal representation of time, and mean absolute error as a loss function.\n",
        "\n",
        "Defining a custom loss which is closer to the common sense loss of the problem we might achieve a better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w07TRQoYPpx4"
      },
      "source": [
        "#### Predict hours and minutes using decimal representation and custom loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQvpFV_jVrEq",
        "outputId": "624bf847-58f9-4c0d-b091-8726d738181a"
      },
      "source": [
        "y_decimal_train = decimal_representation_of(y_train)\n",
        "y_decimal_valid = decimal_representation_of(y_valid)\n",
        "y_decimal_test = decimal_representation_of(y_test)\n",
        "\n",
        "dataset = Dataset(\n",
        "      name='decimal-representation-common-sense-loss',\n",
        "      input_shape=input_shape,\n",
        "      x_train=x_train,\n",
        "      y_train=y_decimal_train,\n",
        "      x_valid=x_valid,\n",
        "      y_valid=y_decimal_valid,\n",
        "      x_test=x_test,\n",
        "      y_test=y_decimal_test,\n",
        "  )\n",
        "\n",
        "decimal_hours_minutes_custom_loss_model = regression_cnn_1(DecimalTimesMeanLoss(), dataset, 1, mean_minutes_loss_metric)\n",
        "train(decimal_hours_minutes_custom_loss_model, dataset)\n",
        "print(f'Minutes loss on test set: {evaluate(decimal_hours_minutes_custom_loss_model, dataset.x_test, dataset.y_test)[1]}')\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_9 (Rescaling)     (None, 150, 150, 1)       0         \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 146, 146, 16)      416       \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 73, 73, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (None, 71, 71, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (None, 69, 69, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 34, 34, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_48 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_49 (Conv2D)          (None, 30, 30, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 15, 15, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 14400)             0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 512)               7373312   \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,706,209\n",
            "Trainable params: 7,706,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 45ms/step - loss: 3.1677 - mean_minutes_loss_metric: 189.9588 - val_loss: 3.0189 - val_mean_minutes_loss_metric: 181.0632\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 3.0097 - mean_minutes_loss_metric: 180.6084 - val_loss: 2.9140 - val_mean_minutes_loss_metric: 174.9130\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 3.0368 - mean_minutes_loss_metric: 182.1337 - val_loss: 3.0590 - val_mean_minutes_loss_metric: 183.4358\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 3.0254 - mean_minutes_loss_metric: 181.5726 - val_loss: 3.0890 - val_mean_minutes_loss_metric: 185.2484\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 3.0121 - mean_minutes_loss_metric: 180.6396 - val_loss: 2.9233 - val_mean_minutes_loss_metric: 175.4437\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 3.0105 - mean_minutes_loss_metric: 180.6378 - val_loss: 2.9416 - val_mean_minutes_loss_metric: 176.5136\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 2.9702 - mean_minutes_loss_metric: 178.0427 - val_loss: 2.7494 - val_mean_minutes_loss_metric: 164.9503\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 2.6066 - mean_minutes_loss_metric: 156.4402 - val_loss: 2.4201 - val_mean_minutes_loss_metric: 145.1853\n",
            "Epoch 9/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 2.1609 - mean_minutes_loss_metric: 129.7001 - val_loss: 2.2032 - val_mean_minutes_loss_metric: 132.0529\n",
            "Epoch 10/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 1.8254 - mean_minutes_loss_metric: 109.5586 - val_loss: 1.7031 - val_mean_minutes_loss_metric: 102.0126\n",
            "Epoch 11/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 1.4852 - mean_minutes_loss_metric: 89.0874 - val_loss: 1.3820 - val_mean_minutes_loss_metric: 82.8652\n",
            "Epoch 12/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 1.2939 - mean_minutes_loss_metric: 77.6719 - val_loss: 1.2530 - val_mean_minutes_loss_metric: 75.1234\n",
            "Epoch 13/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 1.0918 - mean_minutes_loss_metric: 65.4542 - val_loss: 1.0778 - val_mean_minutes_loss_metric: 64.6841\n",
            "Epoch 14/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.9102 - mean_minutes_loss_metric: 54.5510 - val_loss: 0.8201 - val_mean_minutes_loss_metric: 49.1814\n",
            "Epoch 15/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.7420 - mean_minutes_loss_metric: 44.5093 - val_loss: 0.7353 - val_mean_minutes_loss_metric: 44.1057\n",
            "Epoch 16/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.6597 - mean_minutes_loss_metric: 39.6120 - val_loss: 0.6383 - val_mean_minutes_loss_metric: 38.2516\n",
            "Epoch 17/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.5616 - mean_minutes_loss_metric: 33.7185 - val_loss: 0.5486 - val_mean_minutes_loss_metric: 32.8906\n",
            "Epoch 18/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.5263 - mean_minutes_loss_metric: 31.5699 - val_loss: 0.5250 - val_mean_minutes_loss_metric: 31.5244\n",
            "Epoch 19/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.5016 - mean_minutes_loss_metric: 30.0684 - val_loss: 0.4778 - val_mean_minutes_loss_metric: 28.6757\n",
            "Epoch 20/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.4198 - mean_minutes_loss_metric: 25.1699 - val_loss: 0.4525 - val_mean_minutes_loss_metric: 27.1070\n",
            "Epoch 21/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.4001 - mean_minutes_loss_metric: 23.9884 - val_loss: 0.4121 - val_mean_minutes_loss_metric: 24.7316\n",
            "Epoch 22/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.3795 - mean_minutes_loss_metric: 22.7641 - val_loss: 0.4015 - val_mean_minutes_loss_metric: 24.0689\n",
            "Epoch 23/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.3516 - mean_minutes_loss_metric: 21.0733 - val_loss: 0.3563 - val_mean_minutes_loss_metric: 21.3721\n",
            "Epoch 24/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.3261 - mean_minutes_loss_metric: 19.6032 - val_loss: 0.4194 - val_mean_minutes_loss_metric: 25.1365\n",
            "Epoch 25/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.3169 - mean_minutes_loss_metric: 18.9991 - val_loss: 0.3453 - val_mean_minutes_loss_metric: 20.7083\n",
            "Epoch 26/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2949 - mean_minutes_loss_metric: 17.6778 - val_loss: 0.3260 - val_mean_minutes_loss_metric: 19.5551\n",
            "Epoch 27/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.2797 - mean_minutes_loss_metric: 16.7714 - val_loss: 0.3576 - val_mean_minutes_loss_metric: 21.4255\n",
            "Epoch 28/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.2761 - mean_minutes_loss_metric: 16.5728 - val_loss: 0.3412 - val_mean_minutes_loss_metric: 20.4546\n",
            "Epoch 29/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2646 - mean_minutes_loss_metric: 15.8735 - val_loss: 0.2982 - val_mean_minutes_loss_metric: 17.8828\n",
            "Epoch 30/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2626 - mean_minutes_loss_metric: 15.7451 - val_loss: 0.3061 - val_mean_minutes_loss_metric: 18.3508\n",
            "Epoch 31/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2472 - mean_minutes_loss_metric: 14.8201 - val_loss: 0.2963 - val_mean_minutes_loss_metric: 17.7669\n",
            "Epoch 32/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2572 - mean_minutes_loss_metric: 15.4602 - val_loss: 0.3760 - val_mean_minutes_loss_metric: 22.5594\n",
            "Epoch 33/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2413 - mean_minutes_loss_metric: 14.5049 - val_loss: 0.3350 - val_mean_minutes_loss_metric: 20.0845\n",
            "Epoch 34/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2288 - mean_minutes_loss_metric: 13.7187 - val_loss: 0.3373 - val_mean_minutes_loss_metric: 20.2290\n",
            "Epoch 35/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2147 - mean_minutes_loss_metric: 12.8677 - val_loss: 0.3048 - val_mean_minutes_loss_metric: 18.2638\n",
            "Epoch 36/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2124 - mean_minutes_loss_metric: 12.7554 - val_loss: 0.2816 - val_mean_minutes_loss_metric: 16.9028\n",
            "Epoch 37/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2238 - mean_minutes_loss_metric: 13.4244 - val_loss: 0.2846 - val_mean_minutes_loss_metric: 17.0418\n",
            "Epoch 38/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1914 - mean_minutes_loss_metric: 11.4836 - val_loss: 0.2818 - val_mean_minutes_loss_metric: 16.8984\n",
            "Epoch 39/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1953 - mean_minutes_loss_metric: 11.7052 - val_loss: 0.2464 - val_mean_minutes_loss_metric: 14.7723\n",
            "Epoch 40/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.1878 - mean_minutes_loss_metric: 11.2652 - val_loss: 0.2690 - val_mean_minutes_loss_metric: 16.1209\n",
            "Epoch 41/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1874 - mean_minutes_loss_metric: 11.2400 - val_loss: 0.2932 - val_mean_minutes_loss_metric: 17.5745\n",
            "Epoch 42/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2028 - mean_minutes_loss_metric: 12.1717 - val_loss: 0.2920 - val_mean_minutes_loss_metric: 17.4808\n",
            "Epoch 43/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1879 - mean_minutes_loss_metric: 11.2737 - val_loss: 0.2606 - val_mean_minutes_loss_metric: 15.6155\n",
            "Epoch 44/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1732 - mean_minutes_loss_metric: 10.3911 - val_loss: 0.2726 - val_mean_minutes_loss_metric: 16.3332\n",
            "Epoch 45/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.1789 - mean_minutes_loss_metric: 10.7364 - val_loss: 0.2928 - val_mean_minutes_loss_metric: 17.5394\n",
            "Epoch 46/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1694 - mean_minutes_loss_metric: 10.1589 - val_loss: 0.2583 - val_mean_minutes_loss_metric: 15.4741\n",
            "Epoch 47/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1628 - mean_minutes_loss_metric: 9.7843 - val_loss: 0.2687 - val_mean_minutes_loss_metric: 16.1050\n",
            "Epoch 48/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1708 - mean_minutes_loss_metric: 10.2497 - val_loss: 0.2614 - val_mean_minutes_loss_metric: 15.6625\n",
            "Epoch 49/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1670 - mean_minutes_loss_metric: 10.0188 - val_loss: 0.2521 - val_mean_minutes_loss_metric: 15.1256\n",
            "Minutes loss on test set: 15.39694595336914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzehmFbQRI49"
      },
      "source": [
        "##### Observations\n",
        "As expected using the same model with \"common sense\" loss function (the absolute value of the time difference between the predicted and the actual time), we achieved a better accuracy with 15.39 minutes mean loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJtnk24wMZtE"
      },
      "source": [
        "#### Predict hours only\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHRNPxO9f8l8",
        "outputId": "3703a2bf-ac62-48ba-9c5c-c39ecb42df99"
      },
      "source": [
        "y_hours_train = y_train[:, 0].astype('float32')\n",
        "y_hours_valid = y_valid[:, 0].astype('float32')\n",
        "y_hours_test = y_test[:, 0].astype('float32')\n",
        "\n",
        "dataset = Dataset(\n",
        "      name='hours-common-sense-loss',\n",
        "      input_shape=input_shape,\n",
        "      x_train=x_train,\n",
        "      y_train=y_hours_train,\n",
        "      x_valid=x_valid,\n",
        "      y_valid=y_hours_valid,\n",
        "      x_test=x_test,\n",
        "      y_test=y_hours_test,\n",
        "  )\n",
        "\n",
        "hours_custom_loss_model = regression_cnn_1(DecimalTimesMeanLoss(), dataset, 1)\n",
        "train(hours_custom_loss_model, dataset)\n",
        "print(f'Hours loss on test set: {evaluate(hours_custom_loss_model, dataset.x_test, dataset.y_test)[1] / 60}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_9 (Rescaling)     (None, 150, 150, 1)       0         \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 146, 146, 16)      416       \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 73, 73, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (None, 71, 71, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (None, 69, 69, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 34, 34, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_48 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_49 (Conv2D)          (None, 30, 30, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 15, 15, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 14400)             0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 512)               7373312   \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,706,209\n",
            "Trainable params: 7,706,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 41ms/step - loss: 3.0409 - mean_minutes_loss_metric: 182.4120 - val_loss: 3.0261 - val_mean_minutes_loss_metric: 181.6007\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 2.9721 - mean_minutes_loss_metric: 178.2940 - val_loss: 3.0673 - val_mean_minutes_loss_metric: 184.0084\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 3.0070 - mean_minutes_loss_metric: 180.3841 - val_loss: 2.9791 - val_mean_minutes_loss_metric: 178.7113\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 3.0191 - mean_minutes_loss_metric: 181.0696 - val_loss: 3.0026 - val_mean_minutes_loss_metric: 180.2046\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 3.0191 - mean_minutes_loss_metric: 181.1589 - val_loss: 2.8019 - val_mean_minutes_loss_metric: 168.2238\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 2.5650 - mean_minutes_loss_metric: 153.9084 - val_loss: 2.2902 - val_mean_minutes_loss_metric: 137.3232\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 2.2403 - mean_minutes_loss_metric: 134.4087 - val_loss: 2.2236 - val_mean_minutes_loss_metric: 133.2957\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 2.0696 - mean_minutes_loss_metric: 124.1082 - val_loss: 1.9430 - val_mean_minutes_loss_metric: 116.4808\n",
            "Epoch 9/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 1.8474 - mean_minutes_loss_metric: 110.8817 - val_loss: 1.8478 - val_mean_minutes_loss_metric: 110.8575\n",
            "Epoch 10/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 1.6135 - mean_minutes_loss_metric: 96.8367 - val_loss: 1.3929 - val_mean_minutes_loss_metric: 83.5080\n",
            "Epoch 11/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 1.3924 - mean_minutes_loss_metric: 83.5015 - val_loss: 1.2641 - val_mean_minutes_loss_metric: 75.8124\n",
            "Epoch 12/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 1.2126 - mean_minutes_loss_metric: 72.7864 - val_loss: 1.0966 - val_mean_minutes_loss_metric: 65.7710\n",
            "Epoch 13/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 1.0248 - mean_minutes_loss_metric: 61.4421 - val_loss: 0.7986 - val_mean_minutes_loss_metric: 47.8487\n",
            "Epoch 14/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.8060 - mean_minutes_loss_metric: 48.3373 - val_loss: 0.8086 - val_mean_minutes_loss_metric: 48.4719\n",
            "Epoch 15/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.7254 - mean_minutes_loss_metric: 43.5313 - val_loss: 0.7245 - val_mean_minutes_loss_metric: 43.4312\n",
            "Epoch 16/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.6285 - mean_minutes_loss_metric: 37.6833 - val_loss: 0.5421 - val_mean_minutes_loss_metric: 32.4939\n",
            "Epoch 17/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.5862 - mean_minutes_loss_metric: 35.2045 - val_loss: 0.7506 - val_mean_minutes_loss_metric: 44.9646\n",
            "Epoch 18/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.5533 - mean_minutes_loss_metric: 33.2120 - val_loss: 0.5213 - val_mean_minutes_loss_metric: 31.2390\n",
            "Epoch 19/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.4909 - mean_minutes_loss_metric: 29.4457 - val_loss: 0.4672 - val_mean_minutes_loss_metric: 28.0538\n",
            "Epoch 20/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.4536 - mean_minutes_loss_metric: 27.2212 - val_loss: 0.4499 - val_mean_minutes_loss_metric: 26.9796\n",
            "Epoch 21/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.4418 - mean_minutes_loss_metric: 26.4900 - val_loss: 0.4195 - val_mean_minutes_loss_metric: 25.1412\n",
            "Epoch 22/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.4036 - mean_minutes_loss_metric: 24.1976 - val_loss: 0.3858 - val_mean_minutes_loss_metric: 23.1155\n",
            "Epoch 23/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.3803 - mean_minutes_loss_metric: 22.8032 - val_loss: 0.3553 - val_mean_minutes_loss_metric: 21.2790\n",
            "Epoch 24/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.3490 - mean_minutes_loss_metric: 20.9412 - val_loss: 0.3219 - val_mean_minutes_loss_metric: 19.2823\n",
            "Epoch 25/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.3372 - mean_minutes_loss_metric: 20.2278 - val_loss: 0.3527 - val_mean_minutes_loss_metric: 21.1110\n",
            "Epoch 26/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 0.3484 - mean_minutes_loss_metric: 20.8825 - val_loss: 0.3730 - val_mean_minutes_loss_metric: 22.3396\n",
            "Epoch 27/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.3435 - mean_minutes_loss_metric: 20.6014 - val_loss: 0.3466 - val_mean_minutes_loss_metric: 20.7491\n",
            "Epoch 28/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.3075 - mean_minutes_loss_metric: 18.4546 - val_loss: 0.3145 - val_mean_minutes_loss_metric: 18.8483\n",
            "Epoch 29/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.3122 - mean_minutes_loss_metric: 18.7180 - val_loss: 0.3594 - val_mean_minutes_loss_metric: 21.5307\n",
            "Epoch 30/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.3022 - mean_minutes_loss_metric: 18.1298 - val_loss: 0.2897 - val_mean_minutes_loss_metric: 17.3558\n",
            "Epoch 31/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.2968 - mean_minutes_loss_metric: 17.7987 - val_loss: 0.3233 - val_mean_minutes_loss_metric: 19.3639\n",
            "Epoch 32/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 0.2865 - mean_minutes_loss_metric: 17.1806 - val_loss: 0.2922 - val_mean_minutes_loss_metric: 17.5081\n",
            "Epoch 33/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.2562 - mean_minutes_loss_metric: 15.3669 - val_loss: 0.2585 - val_mean_minutes_loss_metric: 15.4927\n",
            "Epoch 34/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.2679 - mean_minutes_loss_metric: 16.0677 - val_loss: 0.2924 - val_mean_minutes_loss_metric: 17.5172\n",
            "Epoch 35/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.2684 - mean_minutes_loss_metric: 16.1002 - val_loss: 0.3665 - val_mean_minutes_loss_metric: 21.9707\n",
            "Epoch 36/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.2561 - mean_minutes_loss_metric: 15.3701 - val_loss: 0.2745 - val_mean_minutes_loss_metric: 16.4632\n",
            "Epoch 37/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.2493 - mean_minutes_loss_metric: 14.9711 - val_loss: 0.2779 - val_mean_minutes_loss_metric: 16.6417\n",
            "Epoch 38/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.2513 - mean_minutes_loss_metric: 15.0740 - val_loss: 0.3031 - val_mean_minutes_loss_metric: 18.1524\n",
            "Epoch 39/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.2423 - mean_minutes_loss_metric: 14.5380 - val_loss: 0.2775 - val_mean_minutes_loss_metric: 16.6182\n",
            "Epoch 40/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.2344 - mean_minutes_loss_metric: 14.0533 - val_loss: 0.2480 - val_mean_minutes_loss_metric: 14.8640\n",
            "Epoch 41/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.2202 - mean_minutes_loss_metric: 13.2210 - val_loss: 0.2589 - val_mean_minutes_loss_metric: 15.5244\n",
            "Epoch 42/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.2394 - mean_minutes_loss_metric: 14.3685 - val_loss: 0.2975 - val_mean_minutes_loss_metric: 17.8280\n",
            "Epoch 43/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.2273 - mean_minutes_loss_metric: 13.6328 - val_loss: 0.2589 - val_mean_minutes_loss_metric: 15.5176\n",
            "Epoch 44/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.2153 - mean_minutes_loss_metric: 12.9136 - val_loss: 0.2504 - val_mean_minutes_loss_metric: 14.9975\n",
            "Epoch 45/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 0.2185 - mean_minutes_loss_metric: 13.0971 - val_loss: 0.2468 - val_mean_minutes_loss_metric: 14.7850\n",
            "Epoch 46/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.2034 - mean_minutes_loss_metric: 12.2042 - val_loss: 0.2881 - val_mean_minutes_loss_metric: 17.2665\n",
            "Epoch 47/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.2139 - mean_minutes_loss_metric: 12.8333 - val_loss: 0.2776 - val_mean_minutes_loss_metric: 16.6396\n",
            "Epoch 48/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.2115 - mean_minutes_loss_metric: 12.6815 - val_loss: 0.2596 - val_mean_minutes_loss_metric: 15.5437\n",
            "Epoch 49/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.1987 - mean_minutes_loss_metric: 11.9260 - val_loss: 0.2685 - val_mean_minutes_loss_metric: 16.0818\n",
            "Epoch 50/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 0.1927 - mean_minutes_loss_metric: 11.5714 - val_loss: 0.2386 - val_mean_minutes_loss_metric: 14.2904\n",
            "Minutes loss on test set: 14.737452507019043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spb2qawYRtva"
      },
      "source": [
        "##### Observations\n",
        "Applying Regression only in hours with the common sense loss we achieved approximately 15 minutes difference between the actual and the predicted hours"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4LwMe4IMhFo"
      },
      "source": [
        "#### Predict minutes only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WjAQl51hVyu",
        "outputId": "dd9a46af-5301-4141-9eea-bdb8b302662c"
      },
      "source": [
        "y_minutes_train = y_train[:, 1].astype('float32')\n",
        "y_minutes_valid = y_valid[:, 1].astype('float32')\n",
        "y_minutes_test = y_test[:, 1].astype('float32')\n",
        "\n",
        "dataset = Dataset(\n",
        "      name='minutes-common-sense-loss',\n",
        "      input_shape=input_shape,\n",
        "      x_train=x_train,\n",
        "      y_train=y_minutes_train,\n",
        "      x_valid=x_valid,\n",
        "      y_valid=y_minutes_valid,\n",
        "      x_test=x_test,\n",
        "      y_test=y_minutes_test,\n",
        "  )\n",
        "\n",
        "minutes_custom_loss_model = regression_cnn_1(MinutesMeanLoss(), dataset, 1)\n",
        "train(minutes_custom_loss_model, dataset)\n",
        "print(f'Minutes loss on test set: {evaluate(minutes_custom_loss_model, dataset.x_test, dataset.y_test)}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_12 (Rescaling)    (None, 150, 150, 1)       0         \n",
            "                                                                 \n",
            " conv2d_60 (Conv2D)          (None, 146, 146, 16)      416       \n",
            "                                                                 \n",
            " max_pooling2d_36 (MaxPoolin  (None, 73, 73, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_61 (Conv2D)          (None, 71, 71, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_62 (Conv2D)          (None, 69, 69, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_37 (MaxPoolin  (None, 34, 34, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_63 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_64 (Conv2D)          (None, 30, 30, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_38 (MaxPoolin  (None, 15, 15, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 14400)             0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 512)               7373312   \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,706,209\n",
            "Trainable params: 7,706,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 41ms/step - loss: 15.0015 - val_loss: 14.9938\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 14.9665 - val_loss: 15.1373\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 14.9882 - val_loss: 15.1339\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 14.9472 - val_loss: 15.0899\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 14.9401 - val_loss: 14.9050\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 14.9643 - val_loss: 15.0464\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 14.5551 - val_loss: 13.4855\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 12.7937 - val_loss: 11.8496\n",
            "Epoch 9/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 10.9167 - val_loss: 10.4057\n",
            "Epoch 10/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 10.0916 - val_loss: 9.6206\n",
            "Epoch 11/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 8.9894 - val_loss: 8.6107\n",
            "Epoch 12/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 8.2151 - val_loss: 7.4146\n",
            "Epoch 13/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 7.4143 - val_loss: 7.2616\n",
            "Epoch 14/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 6.7249 - val_loss: 6.5509\n",
            "Epoch 15/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 6.1809 - val_loss: 5.9096\n",
            "Epoch 16/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 5.7636 - val_loss: 5.7645\n",
            "Epoch 17/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 5.3395 - val_loss: 5.4073\n",
            "Epoch 18/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 4.9800 - val_loss: 5.5039\n",
            "Epoch 19/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 4.7366 - val_loss: 4.6078\n",
            "Epoch 20/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 4.5124 - val_loss: 4.3471\n",
            "Epoch 21/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 4.3076 - val_loss: 4.5676\n",
            "Epoch 22/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 3.9682 - val_loss: 4.4477\n",
            "Epoch 23/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 3.7718 - val_loss: 4.0713\n",
            "Epoch 24/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 3.6130 - val_loss: 4.2423\n",
            "Epoch 25/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 3.5516 - val_loss: 3.6023\n",
            "Epoch 26/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 3.3621 - val_loss: 3.5295\n",
            "Epoch 27/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 3.4006 - val_loss: 3.6775\n",
            "Epoch 28/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 3.1114 - val_loss: 3.7117\n",
            "Epoch 29/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 3.0855 - val_loss: 3.5184\n",
            "Epoch 30/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 2.9725 - val_loss: 3.8034\n",
            "Epoch 31/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 2.9553 - val_loss: 3.3451\n",
            "Epoch 32/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 2.8458 - val_loss: 3.3565\n",
            "Epoch 33/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 2.6207 - val_loss: 3.2408\n",
            "Epoch 34/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 2.6490 - val_loss: 3.2017\n",
            "Epoch 35/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 2.5483 - val_loss: 3.3299\n",
            "Epoch 36/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 2.4083 - val_loss: 3.0085\n",
            "Epoch 37/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 2.3854 - val_loss: 3.0982\n",
            "Epoch 38/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 2.4238 - val_loss: 3.1062\n",
            "Epoch 39/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 2.3008 - val_loss: 2.9869\n",
            "Epoch 40/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 2.2513 - val_loss: 3.0249\n",
            "Epoch 41/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 2.2607 - val_loss: 3.1969\n",
            "Epoch 42/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 2.1275 - val_loss: 2.8638\n",
            "Epoch 43/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 2.0892 - val_loss: 2.8313\n",
            "Epoch 44/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 2.1266 - val_loss: 3.0563\n",
            "Epoch 45/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 2.0688 - val_loss: 2.9089\n",
            "Epoch 46/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 2.0094 - val_loss: 2.9088\n",
            "Epoch 47/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 2.2055 - val_loss: 3.0375\n",
            "Epoch 48/50\n",
            "96/96 [==============================] - 4s 37ms/step - loss: 2.0434 - val_loss: 2.9372\n",
            "Epoch 49/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 1.8780 - val_loss: 2.7113\n",
            "Epoch 50/50\n",
            "96/96 [==============================] - 4s 38ms/step - loss: 1.9708 - val_loss: 2.7927\n",
            "Minutes loss on test set: 2.877833604812622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5nmBGsqSEBJ"
      },
      "source": [
        "##### Observations\n",
        "Predicting only the minutes by using the regression model with common sense loss,\n",
        "less than 3 minutes loss was recorded on the test set. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVJP1j3_NOpj"
      },
      "source": [
        "### Cyclical representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOXM9s_pIZz5"
      },
      "source": [
        "def get_angle(sin, cos):\n",
        "    angle = math.atan2(sin, cos) * 180 / math.pi # ALWAYS USE THIS\n",
        "    \n",
        "    if angle < 0: \n",
        "        angle += 360\n",
        "    \n",
        "    return angle\n",
        "\n",
        "\n",
        "def get_minutes(sin, cos, max_value):\n",
        "    \n",
        "    return int(get_angle(sin, cos)*max_value*1.0/180)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFumhqjKMqj2"
      },
      "source": [
        "#### Predict hours and minutes with cyclical representation (sine, cosine)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWUOv1AnlIfi",
        "outputId": "f0199486-2917-413a-9514-da2e8ea55dfd"
      },
      "source": [
        "\n",
        "y_cyclical_train = cyclical_representation_of(y_train).T\n",
        "y_cyclical_valid = cyclical_representation_of(y_valid).T\n",
        "y_cyclical_test = cyclical_representation_of(y_test).T\n",
        "\n",
        "print(y_cyclical_train.shape)\n",
        "print(y_cyclical_train[0])\n",
        "print(y_cyclical_valid.shape)\n",
        "print(y_cyclical_test.shape)\n",
        "print(x_train.shape)\n",
        "# y_decimal_train.shape\n",
        "\n",
        "dataset = Dataset(\n",
        "      name='cyclical-representation',\n",
        "      input_shape=input_shape,\n",
        "      x_train=x_train,\n",
        "      y_train=y_cyclical_train,\n",
        "      x_valid=x_valid,\n",
        "      y_valid=y_cyclical_valid,\n",
        "      x_test=x_test,\n",
        "      y_test=y_cyclical_test\n",
        "  )\n",
        "\n",
        "cyclical_time_custom_loss_model = regression_cnn_1('mae', dataset, 2)\n",
        "train(cyclical_time_custom_loss_model, dataset)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12240, 2)\n",
            "[-0.9998477   0.01745241]\n",
            "(2160, 2)\n",
            "(3600, 2)\n",
            "(12240, 150, 150, 1)\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_6 (Rescaling)     (None, 150, 150, 1)       0         \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 146, 146, 16)      416       \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 73, 73, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 71, 71, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 69, 69, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 34, 34, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 30, 30, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 15, 15, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 14400)             0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 512)               7373312   \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,706,722\n",
            "Trainable params: 7,706,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 43ms/step - loss: 0.6353 - val_loss: 0.6065\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.5570 - val_loss: 0.5276\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.5116 - val_loss: 0.5014\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.4933 - val_loss: 0.4805\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.4648 - val_loss: 0.4394\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.4225 - val_loss: 0.3889\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.3739 - val_loss: 0.3623\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.3256 - val_loss: 0.3147\n",
            "Epoch 9/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2880 - val_loss: 0.2685\n",
            "Epoch 10/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2486 - val_loss: 0.2169\n",
            "Epoch 11/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2274 - val_loss: 0.1856\n",
            "Epoch 12/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1792 - val_loss: 0.1624\n",
            "Epoch 13/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1581 - val_loss: 0.1390\n",
            "Epoch 14/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1338 - val_loss: 0.1198\n",
            "Epoch 15/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1240 - val_loss: 0.1109\n",
            "Epoch 16/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1117 - val_loss: 0.1210\n",
            "Epoch 17/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1060 - val_loss: 0.0931\n",
            "Epoch 18/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0974 - val_loss: 0.0932\n",
            "Epoch 19/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0917 - val_loss: 0.0909\n",
            "Epoch 20/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0854 - val_loss: 0.0814\n",
            "Epoch 21/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0800 - val_loss: 0.0894\n",
            "Epoch 22/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0763 - val_loss: 0.0750\n",
            "Epoch 23/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0747 - val_loss: 0.0783\n",
            "Epoch 24/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0728 - val_loss: 0.0756\n",
            "Epoch 25/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0730 - val_loss: 0.0759\n",
            "Epoch 26/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0681 - val_loss: 0.0721\n",
            "Epoch 27/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0647 - val_loss: 0.0653\n",
            "Epoch 28/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0601 - val_loss: 0.0644\n",
            "Epoch 29/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0612 - val_loss: 0.0652\n",
            "Epoch 30/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0585 - val_loss: 0.0642\n",
            "Epoch 31/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0596 - val_loss: 0.0610\n",
            "Epoch 32/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0598 - val_loss: 0.0628\n",
            "Epoch 33/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0587 - val_loss: 0.0617\n",
            "Epoch 34/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0540 - val_loss: 0.0646\n",
            "Epoch 35/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0545 - val_loss: 0.0527\n",
            "Epoch 36/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0523 - val_loss: 0.0551\n",
            "Epoch 37/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0527 - val_loss: 0.0547\n",
            "Epoch 38/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0511 - val_loss: 0.0588\n",
            "Epoch 39/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0506 - val_loss: 0.0545\n",
            "Epoch 40/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0493 - val_loss: 0.0531\n",
            "Epoch 41/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0480 - val_loss: 0.0541\n",
            "Epoch 42/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0493 - val_loss: 0.0610\n",
            "Epoch 43/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0481 - val_loss: 0.0485\n",
            "Epoch 44/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0473 - val_loss: 0.0537\n",
            "Epoch 45/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0483 - val_loss: 0.0538\n",
            "Epoch 46/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0476 - val_loss: 0.0558\n",
            "Epoch 47/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0465 - val_loss: 0.0614\n",
            "Epoch 48/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0452 - val_loss: 0.0449\n",
            "Epoch 49/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0476 - val_loss: 0.0484\n",
            "Epoch 50/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0463 - val_loss: 0.0514\n",
            "Minutes loss on test set: 0.0512809157371521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YC729izIufV",
        "outputId": "527792a5-e3b3-442c-87d0-a2c8d7085ef2"
      },
      "source": [
        "y_pred_cyclical = cyclical_time_custom_loss_model.predict(x_test)\n",
        "\n",
        "adjusted_mae_numpy(\n",
        "    np.array([get_minutes(sin, cos, 720) for (sin, cos) in y_pred_cyclical]).reshape(-1, 1), \n",
        "    np.array([get_minutes(sin, cos, 720) for (sin, cos) in y_cyclical_test]).reshape(-1, 1),\n",
        "    720\n",
        "    )"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.055"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvlDTawuMzBp"
      },
      "source": [
        "#### Predict hours with cyclical representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeAXa5qRIGOZ",
        "outputId": "849e1392-c32b-4ca1-fec2-4d47c4b95689"
      },
      "source": [
        "y_cyclical_hours_train = cyclical_representation_of_hours(y_train[:,0]).T\n",
        "y_cyclical_hours_valid = cyclical_representation_of_hours(y_valid[:,0]).T\n",
        "y_cyclical_hours_test = cyclical_representation_of_hours(y_test[:,0]).T\n",
        "\n",
        "dataset = Dataset(\n",
        "      name='hours-cyclical-representation',\n",
        "      input_shape=input_shape,\n",
        "      x_train=x_train,\n",
        "      y_train=y_cyclical_hours_train,\n",
        "      x_valid=x_valid,\n",
        "      y_valid=y_cyclical_hours_valid,\n",
        "      x_test=x_test,\n",
        "      y_test=y_cyclical_hours_test\n",
        "  )\n",
        "\n",
        "\n",
        "cyclical_hours_custom_loss_model = regression_cnn_1('mae', dataset, 2)\n",
        "train(cyclical_hours_custom_loss_model, dataset)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_10 (Rescaling)    (None, 150, 150, 1)       0         \n",
            "                                                                 \n",
            " conv2d_50 (Conv2D)          (None, 146, 146, 16)      416       \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (None, 73, 73, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_51 (Conv2D)          (None, 71, 71, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (None, 69, 69, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (None, 34, 34, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_54 (Conv2D)          (None, 30, 30, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPoolin  (None, 15, 15, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 14400)             0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 512)               7373312   \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,706,722\n",
            "Trainable params: 7,706,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 44ms/step - loss: 0.6259 - val_loss: 0.5631\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.5509 - val_loss: 0.5172\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.5154 - val_loss: 0.5097\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.4898 - val_loss: 0.4749\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.4488 - val_loss: 0.4053\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.4040 - val_loss: 0.3767\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.3544 - val_loss: 0.3491\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.3265 - val_loss: 0.3033\n",
            "Epoch 9/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2939 - val_loss: 0.2722\n",
            "Epoch 10/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2503 - val_loss: 0.2424\n",
            "Epoch 11/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2251 - val_loss: 0.1932\n",
            "Epoch 12/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1952 - val_loss: 0.1842\n",
            "Epoch 13/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1754 - val_loss: 0.1598\n",
            "Epoch 14/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1545 - val_loss: 0.1527\n",
            "Epoch 15/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1471 - val_loss: 0.1460\n",
            "Epoch 16/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1333 - val_loss: 0.1322\n",
            "Epoch 17/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1261 - val_loss: 0.1235\n",
            "Epoch 18/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1229 - val_loss: 0.1243\n",
            "Epoch 19/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1150 - val_loss: 0.1326\n",
            "Epoch 20/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1086 - val_loss: 0.1143\n",
            "Epoch 21/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1032 - val_loss: 0.1036\n",
            "Epoch 22/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0975 - val_loss: 0.1091\n",
            "Epoch 23/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0940 - val_loss: 0.0987\n",
            "Epoch 24/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0927 - val_loss: 0.1043\n",
            "Epoch 25/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0885 - val_loss: 0.0920\n",
            "Epoch 26/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0856 - val_loss: 0.0925\n",
            "Epoch 27/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0857 - val_loss: 0.0975\n",
            "Epoch 28/50\n",
            "96/96 [==============================] - 4s 42ms/step - loss: 0.0817 - val_loss: 0.1049\n",
            "Epoch 29/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0810 - val_loss: 0.0881\n",
            "Epoch 30/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0782 - val_loss: 0.0868\n",
            "Epoch 31/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0777 - val_loss: 0.0854\n",
            "Epoch 32/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0763 - val_loss: 0.0852\n",
            "Epoch 33/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0744 - val_loss: 0.0862\n",
            "Epoch 34/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0767 - val_loss: 0.0790\n",
            "Epoch 35/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0713 - val_loss: 0.0836\n",
            "Epoch 36/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0694 - val_loss: 0.0760\n",
            "Epoch 37/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0723 - val_loss: 0.0801\n",
            "Epoch 38/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0705 - val_loss: 0.0840\n",
            "Epoch 39/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0687 - val_loss: 0.0789\n",
            "Epoch 40/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0675 - val_loss: 0.0837\n",
            "Epoch 41/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0666 - val_loss: 0.0791\n",
            "Epoch 42/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0631 - val_loss: 0.0741\n",
            "Epoch 43/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0648 - val_loss: 0.0773\n",
            "Epoch 44/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0633 - val_loss: 0.0729\n",
            "Epoch 45/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0621 - val_loss: 0.0757\n",
            "Epoch 46/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0616 - val_loss: 0.0727\n",
            "Epoch 47/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0593 - val_loss: 0.0718\n",
            "Epoch 48/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0612 - val_loss: 0.0724\n",
            "Epoch 49/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0616 - val_loss: 0.0740\n",
            "Epoch 50/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0612 - val_loss: 0.0720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyR3cpkwNyTz",
        "outputId": "e055f7fb-8d79-4877-89b9-428e9f556267"
      },
      "source": [
        "y_pred_cyclical = cyclical_hours_custom_loss_model.predict(x_test)\n",
        "adjusted_mae_numpy(\n",
        "    np.array([get_minutes(sin, cos, 12) for (sin, cos) in y_pred_cyclical]).reshape(-1, 1), \n",
        "    np.array([get_minutes(sin, cos, 12) for (sin, cos) in y_cyclical_test]).reshape(-1, 1),\n",
        "    12\n",
        "    )"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.2444444444444445"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUfu3QKfNBa0"
      },
      "source": [
        "#### Predict minutes with cyclical representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5m95L88OMme",
        "outputId": "090f6926-b6c4-4015-eca5-926188b3a4c6"
      },
      "source": [
        "y_cyclical_minutes_train = cyclical_representation_of_minutes(y_train[:,1]).T\n",
        "y_cyclical_minutes_valid = cyclical_representation_of_minutes(y_valid[:,1]).T\n",
        "y_cyclical_minutes_test = cyclical_representation_of_minutes(y_test[:,1]).T\n",
        "\n",
        "dataset = Dataset(\n",
        "      name='minutes-cyclical-representation',\n",
        "      input_shape=input_shape,\n",
        "      x_train=x_train,\n",
        "      y_train=y_cyclical_minutes_train,\n",
        "      x_valid=x_valid,\n",
        "      y_valid=y_cyclical_minutes_valid,\n",
        "      x_test=x_test,\n",
        "      y_test=y_cyclical_minutes_test\n",
        "  )\n",
        "\n",
        "\n",
        "cyclical_minutes_custom_loss_model = regression_cnn_1('mae', dataset, 2)\n",
        "train(cyclical_minutes_custom_loss_model, dataset)\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_11 (Rescaling)    (None, 150, 150, 1)       0         \n",
            "                                                                 \n",
            " conv2d_55 (Conv2D)          (None, 146, 146, 16)      416       \n",
            "                                                                 \n",
            " max_pooling2d_33 (MaxPoolin  (None, 73, 73, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_56 (Conv2D)          (None, 71, 71, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_57 (Conv2D)          (None, 69, 69, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_34 (MaxPoolin  (None, 34, 34, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_58 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_59 (Conv2D)          (None, 30, 30, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_35 (MaxPoolin  (None, 15, 15, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 14400)             0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 512)               7373312   \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,706,722\n",
            "Trainable params: 7,706,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 43ms/step - loss: 0.6664 - val_loss: 0.6379\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.6261 - val_loss: 0.5809\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.5605 - val_loss: 0.5411\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.5251 - val_loss: 0.5282\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.5124 - val_loss: 0.5042\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.4887 - val_loss: 0.4826\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.4704 - val_loss: 0.4342\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.4249 - val_loss: 0.4071\n",
            "Epoch 9/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.3819 - val_loss: 0.3631\n",
            "Epoch 10/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.3503 - val_loss: 0.3032\n",
            "Epoch 11/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.3220 - val_loss: 0.3030\n",
            "Epoch 12/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2938 - val_loss: 0.2737\n",
            "Epoch 13/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2679 - val_loss: 0.2505\n",
            "Epoch 14/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2376 - val_loss: 0.2254\n",
            "Epoch 15/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.2199 - val_loss: 0.1935\n",
            "Epoch 16/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1869 - val_loss: 0.1641\n",
            "Epoch 17/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1647 - val_loss: 0.1487\n",
            "Epoch 18/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1500 - val_loss: 0.1249\n",
            "Epoch 19/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1329 - val_loss: 0.1180\n",
            "Epoch 20/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1198 - val_loss: 0.1084\n",
            "Epoch 21/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1127 - val_loss: 0.1169\n",
            "Epoch 22/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1069 - val_loss: 0.0950\n",
            "Epoch 23/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0983 - val_loss: 0.0911\n",
            "Epoch 24/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0912 - val_loss: 0.0878\n",
            "Epoch 25/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0882 - val_loss: 0.0878\n",
            "Epoch 26/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0878 - val_loss: 0.0785\n",
            "Epoch 27/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0787 - val_loss: 0.0871\n",
            "Epoch 28/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0761 - val_loss: 0.0724\n",
            "Epoch 29/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0700 - val_loss: 0.0698\n",
            "Epoch 30/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0716 - val_loss: 0.0686\n",
            "Epoch 31/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0672 - val_loss: 0.0685\n",
            "Epoch 32/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0640 - val_loss: 0.0641\n",
            "Epoch 33/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0627 - val_loss: 0.0710\n",
            "Epoch 34/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0633 - val_loss: 0.0601\n",
            "Epoch 35/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0604 - val_loss: 0.0655\n",
            "Epoch 36/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0604 - val_loss: 0.0563\n",
            "Epoch 37/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0573 - val_loss: 0.0572\n",
            "Epoch 38/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0593 - val_loss: 0.0631\n",
            "Epoch 39/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0559 - val_loss: 0.0563\n",
            "Epoch 40/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0557 - val_loss: 0.0572\n",
            "Epoch 41/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0568 - val_loss: 0.0589\n",
            "Epoch 42/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0541 - val_loss: 0.0586\n",
            "Epoch 43/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0515 - val_loss: 0.0572\n",
            "Epoch 44/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0506 - val_loss: 0.0516\n",
            "Epoch 45/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0514 - val_loss: 0.0566\n",
            "Epoch 46/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0503 - val_loss: 0.0516\n",
            "Epoch 47/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0481 - val_loss: 0.0514\n",
            "Epoch 48/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0477 - val_loss: 0.0506\n",
            "Epoch 49/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0499 - val_loss: 0.0516\n",
            "Epoch 50/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.0490 - val_loss: 0.0493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2k_3OEqPtCm",
        "outputId": "e938ce46-1628-4992-aca7-0180b2bd10ac"
      },
      "source": [
        "y_pred_cyclical = cyclical_minutes_custom_loss_model.predict(x_test)\n",
        "\n",
        "adjusted_mae_numpy(\n",
        "    np.array([get_minutes(sin, cos, 60) for (sin, cos) in y_pred_cyclical]).reshape(-1, 1), \n",
        "    np.array([get_minutes(sin, cos, 60) for (sin, cos) in y_cyclical_test]).reshape(-1, 1),\n",
        "    60\n",
        "    )"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.920555555555556"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocvU15jPNRoj"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3qdfW35NVno"
      },
      "source": [
        "### Predict hours and minutes as 24 classes, one for each 30 minutes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmYaXEgsJDKE",
        "outputId": "96cd2802-2eda-42a2-8d95-dce7d1977364"
      },
      "source": [
        "y_grouped_train = grouped_in_classes(y_train, 30)\n",
        "y_grouped_test = grouped_in_classes(y_test, 30)\n",
        "y_grouped_valid = grouped_in_classes(y_valid, 30)\n",
        "print(y_grouped_train[0])\n",
        "print(y_train[0])\n",
        "\n",
        "dataset_24 = Dataset(\n",
        "      name='classification',\n",
        "      input_shape=input_shape,\n",
        "      x_train=x_train,\n",
        "      y_train=y_grouped_train,\n",
        "      x_valid=x_valid,\n",
        "      y_valid=y_grouped_valid,\n",
        "      x_test=x_test,\n",
        "      y_test=y_grouped_test\n",
        "  )\n",
        "\n",
        "classification_24_classes_model = classification_cnn(dataset_24, 24)\n",
        "train(classification_24_classes_model, dataset_24)\n",
        "print(f'Accuracy on test set: {evaluate(classification_24_classes_model, dataset_24.x_test, dataset_24.y_test)[1]}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "[9 2]\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling (Rescaling)       (None, 150, 150, 1)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 146, 146, 16)      416       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 73, 73, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 71, 71, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 69, 69, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 34, 34, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 30, 30, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 15, 15, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 14400)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                921664    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 24)                1560      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 997,112\n",
            "Trainable params: 997,112\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 22s 48ms/step - loss: 3.2505 - accuracy: 0.0375 - val_loss: 3.1835 - val_accuracy: 0.0463\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 3.1782 - accuracy: 0.0453 - val_loss: 3.1776 - val_accuracy: 0.0426\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 3.1628 - accuracy: 0.0547 - val_loss: 3.1242 - val_accuracy: 0.0690\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 2.9587 - accuracy: 0.0965 - val_loss: 2.6829 - val_accuracy: 0.1421\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 2.4809 - accuracy: 0.1993 - val_loss: 2.2796 - val_accuracy: 0.2329\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 2.0579 - accuracy: 0.3013 - val_loss: 1.9123 - val_accuracy: 0.3296\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 1.7179 - accuracy: 0.3958 - val_loss: 1.6362 - val_accuracy: 0.4042\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 1.4448 - accuracy: 0.4846 - val_loss: 1.4174 - val_accuracy: 0.4958\n",
            "Epoch 9/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 1.1889 - accuracy: 0.5713 - val_loss: 1.2769 - val_accuracy: 0.5394\n",
            "Epoch 10/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 1.0048 - accuracy: 0.6364 - val_loss: 1.2297 - val_accuracy: 0.5764\n",
            "Epoch 11/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.8929 - accuracy: 0.6728 - val_loss: 1.1295 - val_accuracy: 0.6079\n",
            "Epoch 12/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.7178 - accuracy: 0.7398 - val_loss: 1.0507 - val_accuracy: 0.6394\n",
            "Epoch 13/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.6250 - accuracy: 0.7760 - val_loss: 1.0962 - val_accuracy: 0.6449\n",
            "Epoch 14/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.5233 - accuracy: 0.8106 - val_loss: 0.9333 - val_accuracy: 0.6829\n",
            "Epoch 15/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.4658 - accuracy: 0.8342 - val_loss: 0.9416 - val_accuracy: 0.6898\n",
            "Epoch 16/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.4121 - accuracy: 0.8524 - val_loss: 0.9342 - val_accuracy: 0.7083\n",
            "Epoch 17/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.3565 - accuracy: 0.8767 - val_loss: 0.9627 - val_accuracy: 0.7148\n",
            "Epoch 18/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.3317 - accuracy: 0.8789 - val_loss: 0.9576 - val_accuracy: 0.7236\n",
            "Epoch 19/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.2777 - accuracy: 0.9048 - val_loss: 0.8986 - val_accuracy: 0.7282\n",
            "Epoch 20/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.2646 - accuracy: 0.9089 - val_loss: 0.9362 - val_accuracy: 0.7319\n",
            "Epoch 21/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.2468 - accuracy: 0.9128 - val_loss: 0.8377 - val_accuracy: 0.7630\n",
            "Epoch 22/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.2298 - accuracy: 0.9209 - val_loss: 1.0409 - val_accuracy: 0.7259\n",
            "Epoch 23/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.2268 - accuracy: 0.9221 - val_loss: 0.9151 - val_accuracy: 0.7505\n",
            "Epoch 24/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1981 - accuracy: 0.9296 - val_loss: 0.8762 - val_accuracy: 0.7514\n",
            "Epoch 25/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1955 - accuracy: 0.9346 - val_loss: 0.8609 - val_accuracy: 0.7569\n",
            "Epoch 26/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1636 - accuracy: 0.9444 - val_loss: 0.9220 - val_accuracy: 0.7644\n",
            "Epoch 27/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1802 - accuracy: 0.9351 - val_loss: 0.9012 - val_accuracy: 0.7685\n",
            "Epoch 28/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1620 - accuracy: 0.9422 - val_loss: 0.9521 - val_accuracy: 0.7579\n",
            "Epoch 29/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1528 - accuracy: 0.9472 - val_loss: 0.8796 - val_accuracy: 0.7810\n",
            "Epoch 30/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1592 - accuracy: 0.9476 - val_loss: 0.9249 - val_accuracy: 0.7574\n",
            "Epoch 31/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1413 - accuracy: 0.9503 - val_loss: 0.9306 - val_accuracy: 0.7699\n",
            "Accuracy on test set: 0.7699999809265137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpn1EeOFhgcA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa67da29-7ffc-4d26-d169-19eeae6b07f9"
      },
      "source": [
        "y_test_24 = np.argmax(dataset_24.y_test, axis=1).reshape(-1, 1)\n",
        "\n",
        "y_pred_24 = classification_24_classes_model.predict(dataset_24.x_test)\n",
        "y_pred_24 = np.argmax(y_pred_24, axis=1).reshape(-1, 1)\n",
        "\n",
        "print(f\"MAE: {mean_absolute_error(y_pred_24, y_test_24)}\")\n",
        "print(f\"Adjusted MAE: {adjusted_mae_numpy(y_pred_24, y_test_24, 12)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.8811111111111111\n",
            "Adjusted MAE: 0.5994444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2UwrlRM4lgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08750097-e348-4120-9ef7-a8acf9ee269d"
      },
      "source": [
        "print(classification_report(y_test_24, y_pred_24))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.93      0.82       155\n",
            "           1       0.72      0.69      0.71       133\n",
            "           2       0.82      0.64      0.72       159\n",
            "           3       0.81      0.73      0.77       149\n",
            "           4       0.72      0.72      0.72       158\n",
            "           5       0.83      0.73      0.78       164\n",
            "           6       0.76      0.59      0.66       134\n",
            "           7       0.76      0.83      0.80       145\n",
            "           8       0.65      0.71      0.68       149\n",
            "           9       0.86      0.78      0.82       160\n",
            "          10       0.76      0.85      0.80       143\n",
            "          11       0.75      0.84      0.79       136\n",
            "          12       0.78      0.86      0.82       162\n",
            "          13       0.75      0.75      0.75       151\n",
            "          14       0.92      0.90      0.91       157\n",
            "          15       0.71      0.75      0.73       148\n",
            "          16       0.83      0.84      0.84       167\n",
            "          17       0.73      0.67      0.70       153\n",
            "          18       0.72      0.89      0.79       142\n",
            "          19       0.74      0.73      0.74       149\n",
            "          20       0.83      0.85      0.84       150\n",
            "          21       0.82      0.65      0.72       131\n",
            "          22       0.78      0.84      0.81       146\n",
            "          23       0.76      0.69      0.72       159\n",
            "\n",
            "    accuracy                           0.77      3600\n",
            "   macro avg       0.77      0.77      0.77      3600\n",
            "weighted avg       0.77      0.77      0.77      3600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEYWVuACNc6X"
      },
      "source": [
        "### Predict hours and minutes as 72 classes, one for each 10 minutes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99MNogJNDRep",
        "outputId": "2b81bba8-5da3-4e6a-fbee-190d82f7b931"
      },
      "source": [
        "y_grouped_train = grouped_in_classes(y_train, 10)\n",
        "y_grouped_test = grouped_in_classes(y_test, 10)\n",
        "y_grouped_valid = grouped_in_classes(y_valid, 10)\n",
        "print(y_grouped_train[0])\n",
        "print(y_train[0])\n",
        "\n",
        "dataset_72 = Dataset(\n",
        "      name='classification',\n",
        "      input_shape=input_shape,\n",
        "      x_train=x_train,\n",
        "      y_train=y_grouped_train,\n",
        "      x_valid=x_valid,\n",
        "      y_valid=y_grouped_valid,\n",
        "      x_test=x_test,\n",
        "      y_test=y_grouped_test\n",
        "  )\n",
        "\n",
        "classification_72_classes_model = classification_cnn(dataset_72, 72)\n",
        "train(classification_72_classes_model, dataset_72)\n",
        "print(f'Accuracy on test set: {evaluate(classification_72_classes_model, dataset_72.x_test, dataset_72.y_test)[1]}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[9 2]\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_1 (Rescaling)     (None, 150, 150, 1)       0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 146, 146, 16)      416       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 73, 73, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 71, 71, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 69, 69, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 34, 34, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 30, 30, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 15, 15, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 14400)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                921664    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 72)                4680      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,000,232\n",
            "Trainable params: 1,000,232\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 44ms/step - loss: 4.3358 - accuracy: 0.0138 - val_loss: 4.2848 - val_accuracy: 0.0148\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 4.2833 - accuracy: 0.0154 - val_loss: 4.2836 - val_accuracy: 0.0106\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 4.2805 - accuracy: 0.0168 - val_loss: 4.2738 - val_accuracy: 0.0208\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 4.1995 - accuracy: 0.0261 - val_loss: 4.0368 - val_accuracy: 0.0398\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 3.7112 - accuracy: 0.0798 - val_loss: 3.3655 - val_accuracy: 0.1171\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 2.9638 - accuracy: 0.1922 - val_loss: 2.6728 - val_accuracy: 0.1921\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 2.3194 - accuracy: 0.2951 - val_loss: 2.1847 - val_accuracy: 0.2931\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 1.8467 - accuracy: 0.4043 - val_loss: 1.9711 - val_accuracy: 0.3574\n",
            "Epoch 9/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 1.5211 - accuracy: 0.4901 - val_loss: 1.7292 - val_accuracy: 0.4315\n",
            "Epoch 10/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 1.3098 - accuracy: 0.5547 - val_loss: 1.5586 - val_accuracy: 0.4884\n",
            "Epoch 11/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 1.1044 - accuracy: 0.6238 - val_loss: 1.4216 - val_accuracy: 0.5162\n",
            "Epoch 12/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.9284 - accuracy: 0.6791 - val_loss: 1.3605 - val_accuracy: 0.5454\n",
            "Epoch 13/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.8162 - accuracy: 0.7185 - val_loss: 1.3348 - val_accuracy: 0.5736\n",
            "Epoch 14/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.7201 - accuracy: 0.7475 - val_loss: 1.3109 - val_accuracy: 0.5810\n",
            "Epoch 15/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.6417 - accuracy: 0.7781 - val_loss: 1.3359 - val_accuracy: 0.5903\n",
            "Epoch 16/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.5582 - accuracy: 0.8044 - val_loss: 1.3362 - val_accuracy: 0.6056\n",
            "Epoch 17/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.5015 - accuracy: 0.8249 - val_loss: 1.3062 - val_accuracy: 0.6194\n",
            "Epoch 18/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.4410 - accuracy: 0.8452 - val_loss: 1.4308 - val_accuracy: 0.6116\n",
            "Epoch 19/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.4402 - accuracy: 0.8489 - val_loss: 1.4388 - val_accuracy: 0.6255\n",
            "Epoch 20/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.4028 - accuracy: 0.8619 - val_loss: 1.3797 - val_accuracy: 0.6250\n",
            "Epoch 21/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.3708 - accuracy: 0.8711 - val_loss: 1.5301 - val_accuracy: 0.6120\n",
            "Epoch 22/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.3487 - accuracy: 0.8806 - val_loss: 1.4157 - val_accuracy: 0.6324\n",
            "Epoch 23/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.3192 - accuracy: 0.8913 - val_loss: 1.3704 - val_accuracy: 0.6444\n",
            "Epoch 24/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.3001 - accuracy: 0.8978 - val_loss: 1.4514 - val_accuracy: 0.6301\n",
            "Epoch 25/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.3002 - accuracy: 0.9023 - val_loss: 1.5619 - val_accuracy: 0.6380\n",
            "Epoch 26/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.3193 - accuracy: 0.8922 - val_loss: 1.6968 - val_accuracy: 0.6273\n",
            "Epoch 27/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.3130 - accuracy: 0.8967 - val_loss: 1.6631 - val_accuracy: 0.6421\n",
            "Accuracy on test set: 0.6633333563804626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsNlEXJ6jKQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9efe411-0fcb-46a8-db60-5a8cad1b8c48"
      },
      "source": [
        "y_test_72 = np.argmax(dataset_72.y_test, axis=1).reshape(-1, 1)\n",
        "\n",
        "y_pred_72 = classification_72_classes_model.predict(dataset_72.x_test)\n",
        "y_pred_72 = np.argmax(y_pred_72, axis=1).reshape(-1, 1)\n",
        "\n",
        "print(f\"MAE: {mean_absolute_error(y_pred_72, y_test_72)}\")\n",
        "print(f\"Adjusted MAE: {adjusted_mae_numpy(y_pred_72, y_test_72, 12)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 4.033333333333333\n",
            "Adjusted MAE: 2.823888888888889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3XcL6D34wKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "258d3998-a7c3-4d45-8e8c-c82b95123daf"
      },
      "source": [
        "print(classification_report(y_test_72, y_pred_72))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.64      0.64        66\n",
            "           1       0.63      0.74      0.68        43\n",
            "           2       0.74      0.70      0.72        46\n",
            "           3       0.61      0.52      0.56        42\n",
            "           4       0.72      0.62      0.67        50\n",
            "           5       0.56      0.78      0.65        41\n",
            "           6       0.64      0.66      0.65        44\n",
            "           7       0.79      0.57      0.66        58\n",
            "           8       0.72      0.68      0.70        57\n",
            "           9       0.55      0.78      0.64        50\n",
            "          10       0.57      0.76      0.65        46\n",
            "          11       0.71      0.74      0.72        53\n",
            "          12       0.56      0.76      0.64        49\n",
            "          13       0.46      0.68      0.55        57\n",
            "          14       0.76      0.48      0.59        52\n",
            "          15       0.69      0.43      0.53        58\n",
            "          16       0.63      0.45      0.52        49\n",
            "          17       0.79      0.65      0.71        57\n",
            "          18       0.60      0.53      0.56        40\n",
            "          19       0.62      0.69      0.65        48\n",
            "          20       0.57      0.63      0.60        46\n",
            "          21       0.52      0.73      0.61        51\n",
            "          22       0.69      0.80      0.74        46\n",
            "          23       0.78      0.73      0.75        48\n",
            "          24       0.60      0.71      0.65        49\n",
            "          25       0.66      0.44      0.53        52\n",
            "          26       0.55      0.62      0.58        48\n",
            "          27       0.77      0.63      0.69        52\n",
            "          28       0.78      0.54      0.64        57\n",
            "          29       0.84      0.75      0.79        51\n",
            "          30       0.75      0.81      0.78        48\n",
            "          31       0.56      0.76      0.64        49\n",
            "          32       0.67      0.70      0.68        46\n",
            "          33       0.57      0.67      0.62        43\n",
            "          34       0.55      0.88      0.68        50\n",
            "          35       0.82      0.65      0.73        43\n",
            "          36       0.66      0.86      0.75        44\n",
            "          37       0.87      0.61      0.72        64\n",
            "          38       0.55      0.61      0.58        54\n",
            "          39       0.70      0.61      0.65        57\n",
            "          40       0.80      0.65      0.72        51\n",
            "          41       0.79      0.72      0.76        43\n",
            "          42       0.80      0.69      0.74        54\n",
            "          43       0.63      0.89      0.74        45\n",
            "          44       0.86      0.53      0.66        58\n",
            "          45       0.52      0.60      0.56        40\n",
            "          46       0.49      0.65      0.56        49\n",
            "          47       0.66      0.80      0.72        59\n",
            "          48       0.73      0.55      0.63        66\n",
            "          49       0.68      0.83      0.75        54\n",
            "          50       0.78      0.66      0.71        47\n",
            "          51       0.60      0.61      0.60        51\n",
            "          52       0.58      0.47      0.52        47\n",
            "          53       0.73      0.67      0.70        55\n",
            "          54       0.77      0.69      0.73        49\n",
            "          55       0.73      0.83      0.78        48\n",
            "          56       0.78      0.69      0.73        45\n",
            "          57       0.81      0.62      0.70        61\n",
            "          58       0.49      0.72      0.58        46\n",
            "          59       0.58      0.74      0.65        42\n",
            "          60       0.68      0.74      0.71        58\n",
            "          61       0.76      0.63      0.69        46\n",
            "          62       0.70      0.76      0.73        46\n",
            "          63       0.75      0.60      0.67        45\n",
            "          64       0.50      0.72      0.59        40\n",
            "          65       0.81      0.65      0.72        46\n",
            "          66       0.67      0.65      0.66        49\n",
            "          67       0.71      0.45      0.56        44\n",
            "          68       0.76      0.66      0.71        53\n",
            "          69       0.76      0.63      0.69        62\n",
            "          70       0.72      0.67      0.69        42\n",
            "          71       0.72      0.56      0.63        55\n",
            "\n",
            "    accuracy                           0.66      3600\n",
            "   macro avg       0.68      0.67      0.66      3600\n",
            "weighted avg       0.68      0.66      0.66      3600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czpR3uX4Nlth"
      },
      "source": [
        "### Predict hours as 12 classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52EtTdUNOrvF",
        "outputId": "963de023-718d-4255-b89a-9c33a2e172f2"
      },
      "source": [
        "encoder = OneHotEncoder(sparse=False)\n",
        "y_hours_train = encoder.fit_transform([[yi] for yi in y_train[:,0]])\n",
        "y_hours_valid = encoder.fit_transform([[yi] for yi in y_valid[:,0]])\n",
        "y_hours_test = encoder.fit_transform([[yi] for yi in y_test[:,0]])\n",
        "\n",
        "dataset_12 = Dataset(\n",
        "      name='classification_hours',\n",
        "      input_shape=input_shape,\n",
        "      x_train=x_train,\n",
        "      y_train=y_hours_train,\n",
        "      x_valid=x_valid,\n",
        "      y_valid=y_hours_valid,\n",
        "      x_test=x_test,\n",
        "      y_test=y_hours_test\n",
        "  )\n",
        "\n",
        "categorical_hours_model = classification_cnn(dataset_12, 12, 'categorical_crossentropy')\n",
        "train(categorical_hours_model, dataset_12)\n",
        "print(f'Accuracy on test set: {evaluate(categorical_hours_model, dataset_12.x_test, dataset_12.y_test)[1]}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_4 (Rescaling)     (None, 150, 150, 1)       0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 146, 146, 16)      416       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 73, 73, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 71, 71, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 69, 69, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 34, 34, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 30, 30, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 15, 15, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 14400)             0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 64)                921664    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 12)                780       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 996,332\n",
            "Trainable params: 996,332\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "96/96 [==============================] - 5s 43ms/step - loss: 2.6152 - accuracy: 0.0862 - val_loss: 2.4880 - val_accuracy: 0.0787\n",
            "Epoch 2/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 2.4862 - accuracy: 0.0874 - val_loss: 2.4870 - val_accuracy: 0.0755\n",
            "Epoch 3/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 2.4801 - accuracy: 0.0953 - val_loss: 2.4852 - val_accuracy: 0.0917\n",
            "Epoch 4/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 2.4509 - accuracy: 0.1120 - val_loss: 2.3883 - val_accuracy: 0.1176\n",
            "Epoch 5/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 2.2546 - accuracy: 0.1704 - val_loss: 2.0768 - val_accuracy: 0.2190\n",
            "Epoch 6/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 1.8772 - accuracy: 0.2932 - val_loss: 1.7519 - val_accuracy: 0.3384\n",
            "Epoch 7/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 1.5763 - accuracy: 0.3947 - val_loss: 1.4844 - val_accuracy: 0.4185\n",
            "Epoch 8/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 1.3251 - accuracy: 0.4876 - val_loss: 1.2795 - val_accuracy: 0.5023\n",
            "Epoch 9/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 1.0676 - accuracy: 0.5843 - val_loss: 1.0097 - val_accuracy: 0.6028\n",
            "Epoch 10/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.8815 - accuracy: 0.6522 - val_loss: 0.9178 - val_accuracy: 0.6306\n",
            "Epoch 11/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.7427 - accuracy: 0.7107 - val_loss: 0.8360 - val_accuracy: 0.6741\n",
            "Epoch 12/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.6152 - accuracy: 0.7636 - val_loss: 0.7415 - val_accuracy: 0.7181\n",
            "Epoch 13/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.5192 - accuracy: 0.8013 - val_loss: 0.7064 - val_accuracy: 0.7435\n",
            "Epoch 14/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.4461 - accuracy: 0.8290 - val_loss: 0.5955 - val_accuracy: 0.7801\n",
            "Epoch 15/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.3902 - accuracy: 0.8526 - val_loss: 0.6533 - val_accuracy: 0.7764\n",
            "Epoch 16/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.3108 - accuracy: 0.8841 - val_loss: 0.6497 - val_accuracy: 0.7819\n",
            "Epoch 17/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.3096 - accuracy: 0.8836 - val_loss: 0.5845 - val_accuracy: 0.7949\n",
            "Epoch 18/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.2518 - accuracy: 0.9058 - val_loss: 0.6903 - val_accuracy: 0.7657\n",
            "Epoch 19/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.2516 - accuracy: 0.9053 - val_loss: 0.5685 - val_accuracy: 0.8116\n",
            "Epoch 20/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.2029 - accuracy: 0.9247 - val_loss: 0.6157 - val_accuracy: 0.8102\n",
            "Epoch 21/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1893 - accuracy: 0.9297 - val_loss: 0.6172 - val_accuracy: 0.8032\n",
            "Epoch 22/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1595 - accuracy: 0.9455 - val_loss: 0.5774 - val_accuracy: 0.8194\n",
            "Epoch 23/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1653 - accuracy: 0.9413 - val_loss: 0.5560 - val_accuracy: 0.8292\n",
            "Epoch 24/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1480 - accuracy: 0.9463 - val_loss: 0.5288 - val_accuracy: 0.8514\n",
            "Epoch 25/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1372 - accuracy: 0.9520 - val_loss: 0.7392 - val_accuracy: 0.8051\n",
            "Epoch 26/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1393 - accuracy: 0.9489 - val_loss: 0.5901 - val_accuracy: 0.8366\n",
            "Epoch 27/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1342 - accuracy: 0.9532 - val_loss: 0.5150 - val_accuracy: 0.8310\n",
            "Epoch 28/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1297 - accuracy: 0.9559 - val_loss: 0.5519 - val_accuracy: 0.8435\n",
            "Epoch 29/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1176 - accuracy: 0.9558 - val_loss: 0.5971 - val_accuracy: 0.8449\n",
            "Epoch 30/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1020 - accuracy: 0.9634 - val_loss: 0.5699 - val_accuracy: 0.8324\n",
            "Epoch 31/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1064 - accuracy: 0.9628 - val_loss: 0.5361 - val_accuracy: 0.8560\n",
            "Epoch 32/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1109 - accuracy: 0.9610 - val_loss: 0.5763 - val_accuracy: 0.8523\n",
            "Epoch 33/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1074 - accuracy: 0.9632 - val_loss: 0.6241 - val_accuracy: 0.8449\n",
            "Epoch 34/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.0928 - accuracy: 0.9690 - val_loss: 0.5102 - val_accuracy: 0.8644\n",
            "Epoch 35/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.0872 - accuracy: 0.9709 - val_loss: 0.6170 - val_accuracy: 0.8361\n",
            "Epoch 36/50\n",
            "96/96 [==============================] - 4s 41ms/step - loss: 0.1051 - accuracy: 0.9625 - val_loss: 0.5757 - val_accuracy: 0.8542\n",
            "Epoch 37/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.1024 - accuracy: 0.9650 - val_loss: 0.5474 - val_accuracy: 0.8523\n",
            "Epoch 38/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.0853 - accuracy: 0.9700 - val_loss: 0.5870 - val_accuracy: 0.8505\n",
            "Epoch 39/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.0922 - accuracy: 0.9698 - val_loss: 0.5340 - val_accuracy: 0.8528\n",
            "Epoch 40/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.0728 - accuracy: 0.9752 - val_loss: 0.6256 - val_accuracy: 0.8569\n",
            "Epoch 41/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.0749 - accuracy: 0.9753 - val_loss: 0.6259 - val_accuracy: 0.8532\n",
            "Epoch 42/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.0926 - accuracy: 0.9672 - val_loss: 0.6098 - val_accuracy: 0.8597\n",
            "Epoch 43/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.0858 - accuracy: 0.9707 - val_loss: 0.6563 - val_accuracy: 0.8403\n",
            "Epoch 44/50\n",
            "96/96 [==============================] - 4s 40ms/step - loss: 0.0733 - accuracy: 0.9747 - val_loss: 0.5402 - val_accuracy: 0.8616\n",
            "Accuracy on test set: 0.8666666746139526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViqfwB0JCgsB",
        "outputId": "6091ce2d-567a-4d13-8d74-a66ab22f2adc"
      },
      "source": [
        "y_test_12 = np.argmax(dataset_12.y_test, axis=1).reshape(-1, 1)\n",
        "\n",
        "y_pred_12 = categorical_hours_model.predict(dataset_12.x_test)\n",
        "y_pred_12 = np.argmax(y_pred_12, axis=1).reshape(-1, 1)\n",
        "\n",
        "print(f\"MAE: {mean_absolute_error(y_pred_12, y_test_12)}\")\n",
        "print(f\"Adjusted MAE: {adjusted_mae_numpy(y_pred_12, y_test_12, 12)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.25083333333333335\n",
            "Adjusted MAE: 0.1613888888888889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuHJW7siEAwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2d95335-85ec-4980-f9c2-e8fab9fffccb"
      },
      "source": [
        "print(classification_report(y_test_12, y_pred_12))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.88      0.89       288\n",
            "           1       0.84      0.89      0.86       308\n",
            "           2       0.87      0.82      0.84       322\n",
            "           3       0.86      0.79      0.82       279\n",
            "           4       0.83      0.88      0.85       309\n",
            "           5       0.88      0.87      0.87       279\n",
            "           6       0.86      0.90      0.88       313\n",
            "           7       0.90      0.87      0.89       305\n",
            "           8       0.85      0.88      0.87       320\n",
            "           9       0.89      0.82      0.86       291\n",
            "          10       0.85      0.90      0.87       281\n",
            "          11       0.88      0.90      0.89       305\n",
            "\n",
            "    accuracy                           0.87      3600\n",
            "   macro avg       0.87      0.87      0.87      3600\n",
            "weighted avg       0.87      0.87      0.87      3600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GzrhLAQIoAO"
      },
      "source": [
        "## Multi-head"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXhiTWJyJ53S"
      },
      "source": [
        "def get_y(y):\n",
        "\n",
        "    y_hour = y[:, 0].reshape(-1, 1)\n",
        "    y_minute = y[:, 1].reshape(-1, 1)\n",
        "\n",
        "    y_hour = OneHotEncoder(sparse=False).fit_transform(y_hour)\n",
        "    \n",
        "    return [y_hour, y_minute]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x/255, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI13Zs99VhCm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b35f42e-afaa-4cef-faa2-bb4771bfca95"
      },
      "source": [
        "def get_model(X):\n",
        "    \n",
        "    inp = Input(shape=(X.shape[1], X.shape[2], 1))\n",
        "\n",
        "    # Convolutional Layers\n",
        "    x = Conv2D(64, kernel_size=5, strides=2, activation='leaky_relu')(inp)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), strides=2)(x)\n",
        "    x = Conv2D(64, kernel_size=3, strides=1, activation='leaky_relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Conv2D(64, kernel_size=3, strides=1, activation='leaky_relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Conv2D(64, kernel_size=3, strides=1, activation='leaky_relu')(x)\n",
        "    x = Dropout(.4)(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Hour branch\n",
        "    hour = Dense(256, activation='leaky_relu')(x)\n",
        "    hour = Dense(256, activation='leaky_relu')(hour)\n",
        "    hour = Dense(12, activation='softmax', name='hour')(hour)\n",
        "\n",
        "    # Minute Branch\n",
        "    minute = Dense(256, activation='leaky_relu')(x)\n",
        "    minute = Dense(256, activation='leaky_relu')(minute)    \n",
        "    minute = Dense(1, activation='linear', name='minute')(minute)\n",
        "\n",
        "    model = Model(inputs=inp, outputs=[hour, minute])\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = get_model(x)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 150, 150, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 73, 73, 64)   1664        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 36, 36, 64)  0           ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 34, 34, 64)   36928       ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 17, 17, 64)  0           ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 15, 15, 64)   36928       ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 64)    0           ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 5, 5, 64)     36928       ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 5, 5, 64)     0           ['conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 1600)         0           ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 256)          409856      ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 256)          409856      ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 256)          65792       ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 256)          65792       ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " hour (Dense)                   (None, 12)           3084        ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " minute (Dense)                 (None, 1)            257         ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,067,085\n",
            "Trainable params: 1,067,085\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvJDgcqGV3Qg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35127536-de1f-497a-a85a-81fde9874168"
      },
      "source": [
        "model = get_model(x)\n",
        "\n",
        "model.compile(loss=['categorical_crossentropy', 'mse'], optimizer='adam', metrics=['categorical_accuracy', 'mae'])\n",
        "\n",
        "history = model.fit(x = X_train, y = get_y(y_train), batch_size = 32, epochs = 30, verbose = 1, validation_split = 0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "360/360 [==============================] - 20s 10ms/step - loss: 336.3232 - hour_loss: 2.5176 - minute_loss: 333.8056 - hour_categorical_accuracy: 0.0878 - hour_mae: 0.1528 - minute_categorical_accuracy: 1.0000 - minute_mae: 15.5591 - val_loss: 301.9966 - val_hour_loss: 2.5027 - val_minute_loss: 299.4940 - val_hour_categorical_accuracy: 0.0837 - val_hour_mae: 0.1528 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 14.9843\n",
            "Epoch 2/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 316.8643 - hour_loss: 2.4956 - minute_loss: 314.3687 - hour_categorical_accuracy: 0.0833 - hour_mae: 0.1528 - minute_categorical_accuracy: 1.0000 - minute_mae: 15.2311 - val_loss: 300.0373 - val_hour_loss: 2.4907 - val_minute_loss: 297.5465 - val_hour_categorical_accuracy: 0.0847 - val_hour_mae: 0.1527 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 14.9201\n",
            "Epoch 3/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 293.9734 - hour_loss: 2.4794 - minute_loss: 291.4939 - hour_categorical_accuracy: 0.0925 - hour_mae: 0.1521 - minute_categorical_accuracy: 1.0000 - minute_mae: 14.4360 - val_loss: 280.6971 - val_hour_loss: 2.4218 - val_minute_loss: 278.2753 - val_hour_categorical_accuracy: 0.1111 - val_hour_mae: 0.1507 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 13.5785\n",
            "Epoch 4/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 271.0567 - hour_loss: 2.3420 - minute_loss: 268.7150 - hour_categorical_accuracy: 0.1388 - hour_mae: 0.1481 - minute_categorical_accuracy: 1.0000 - minute_mae: 13.2931 - val_loss: 241.3501 - val_hour_loss: 2.1578 - val_minute_loss: 239.1924 - val_hour_categorical_accuracy: 0.1826 - val_hour_mae: 0.1444 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 12.2511\n",
            "Epoch 5/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 244.4104 - hour_loss: 2.1530 - minute_loss: 242.2574 - hour_categorical_accuracy: 0.1999 - hour_mae: 0.1425 - minute_categorical_accuracy: 1.0000 - minute_mae: 12.3875 - val_loss: 232.9801 - val_hour_loss: 1.9820 - val_minute_loss: 230.9982 - val_hour_categorical_accuracy: 0.2295 - val_hour_mae: 0.1368 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 11.8461\n",
            "Epoch 6/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 227.4254 - hour_loss: 1.9680 - minute_loss: 225.4575 - hour_categorical_accuracy: 0.2468 - hour_mae: 0.1360 - minute_categorical_accuracy: 1.0000 - minute_mae: 11.8082 - val_loss: 220.1862 - val_hour_loss: 1.8078 - val_minute_loss: 218.3784 - val_hour_categorical_accuracy: 0.3076 - val_hour_mae: 0.1287 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 11.4779\n",
            "Epoch 7/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 206.9506 - hour_loss: 1.7715 - minute_loss: 205.1791 - hour_categorical_accuracy: 0.3135 - hour_mae: 0.1278 - minute_categorical_accuracy: 1.0000 - minute_mae: 11.0626 - val_loss: 199.5536 - val_hour_loss: 1.5687 - val_minute_loss: 197.9848 - val_hour_categorical_accuracy: 0.3677 - val_hour_mae: 0.1192 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 10.7611\n",
            "Epoch 8/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 189.9862 - hour_loss: 1.6421 - minute_loss: 188.3442 - hour_categorical_accuracy: 0.3561 - hour_mae: 0.1214 - minute_categorical_accuracy: 1.0000 - minute_mae: 10.3862 - val_loss: 166.3583 - val_hour_loss: 1.4606 - val_minute_loss: 164.8977 - val_hour_categorical_accuracy: 0.4083 - val_hour_mae: 0.1157 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 9.6003\n",
            "Epoch 9/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 164.8457 - hour_loss: 1.4891 - minute_loss: 163.3566 - hour_categorical_accuracy: 0.4138 - hour_mae: 0.1133 - minute_categorical_accuracy: 1.0000 - minute_mae: 9.3759 - val_loss: 156.3414 - val_hour_loss: 1.4040 - val_minute_loss: 154.9374 - val_hour_categorical_accuracy: 0.4340 - val_hour_mae: 0.1120 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 8.9253\n",
            "Epoch 10/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 148.0569 - hour_loss: 1.3816 - minute_loss: 146.6752 - hour_categorical_accuracy: 0.4557 - hour_mae: 0.1070 - minute_categorical_accuracy: 1.0000 - minute_mae: 8.7727 - val_loss: 139.7748 - val_hour_loss: 1.2161 - val_minute_loss: 138.5587 - val_hour_categorical_accuracy: 0.5052 - val_hour_mae: 0.1009 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 8.4435\n",
            "Epoch 11/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 131.3343 - hour_loss: 1.2396 - minute_loss: 130.0946 - hour_categorical_accuracy: 0.5105 - hour_mae: 0.0989 - minute_categorical_accuracy: 1.0000 - minute_mae: 8.0930 - val_loss: 140.3994 - val_hour_loss: 1.0646 - val_minute_loss: 139.3348 - val_hour_categorical_accuracy: 0.5823 - val_hour_mae: 0.0931 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 8.7691\n",
            "Epoch 12/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 114.3314 - hour_loss: 1.1534 - minute_loss: 113.1780 - hour_categorical_accuracy: 0.5407 - hour_mae: 0.0929 - minute_categorical_accuracy: 1.0000 - minute_mae: 7.3574 - val_loss: 112.0037 - val_hour_loss: 1.1288 - val_minute_loss: 110.8750 - val_hour_categorical_accuracy: 0.5302 - val_hour_mae: 0.0903 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 6.9336\n",
            "Epoch 13/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 99.5652 - hour_loss: 1.0512 - minute_loss: 98.5140 - hour_categorical_accuracy: 0.5799 - hour_mae: 0.0865 - minute_categorical_accuracy: 1.0000 - minute_mae: 6.8737 - val_loss: 110.7468 - val_hour_loss: 0.8909 - val_minute_loss: 109.8559 - val_hour_categorical_accuracy: 0.6622 - val_hour_mae: 0.0807 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 6.7983\n",
            "Epoch 14/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 87.3099 - hour_loss: 0.9942 - minute_loss: 86.3157 - hour_categorical_accuracy: 0.6116 - hour_mae: 0.0820 - minute_categorical_accuracy: 1.0000 - minute_mae: 6.2742 - val_loss: 93.1190 - val_hour_loss: 0.8833 - val_minute_loss: 92.2357 - val_hour_categorical_accuracy: 0.6608 - val_hour_mae: 0.0779 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 5.7989\n",
            "Epoch 15/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 76.5067 - hour_loss: 0.8946 - minute_loss: 75.6120 - hour_categorical_accuracy: 0.6478 - hour_mae: 0.0753 - minute_categorical_accuracy: 1.0000 - minute_mae: 5.7841 - val_loss: 101.8344 - val_hour_loss: 0.7464 - val_minute_loss: 101.0880 - val_hour_categorical_accuracy: 0.6955 - val_hour_mae: 0.0687 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 6.7025\n",
            "Epoch 16/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 68.0691 - hour_loss: 0.8447 - minute_loss: 67.2244 - hour_categorical_accuracy: 0.6651 - hour_mae: 0.0713 - minute_categorical_accuracy: 1.0000 - minute_mae: 5.4127 - val_loss: 78.4165 - val_hour_loss: 0.7564 - val_minute_loss: 77.6601 - val_hour_categorical_accuracy: 0.6861 - val_hour_mae: 0.0688 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 5.0916\n",
            "Epoch 17/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 56.7831 - hour_loss: 0.7865 - minute_loss: 55.9966 - hour_categorical_accuracy: 0.6911 - hour_mae: 0.0669 - minute_categorical_accuracy: 1.0000 - minute_mae: 4.9358 - val_loss: 83.0365 - val_hour_loss: 0.7427 - val_minute_loss: 82.2938 - val_hour_categorical_accuracy: 0.7028 - val_hour_mae: 0.0647 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 5.5281\n",
            "Epoch 18/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 55.4723 - hour_loss: 0.7784 - minute_loss: 54.6940 - hour_categorical_accuracy: 0.6929 - hour_mae: 0.0654 - minute_categorical_accuracy: 1.0000 - minute_mae: 4.8539 - val_loss: 65.3088 - val_hour_loss: 0.6688 - val_minute_loss: 64.6399 - val_hour_categorical_accuracy: 0.7285 - val_hour_mae: 0.0625 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 4.5539\n",
            "Epoch 19/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 47.4313 - hour_loss: 0.7196 - minute_loss: 46.7118 - hour_categorical_accuracy: 0.7187 - hour_mae: 0.0610 - minute_categorical_accuracy: 1.0000 - minute_mae: 4.4834 - val_loss: 62.8073 - val_hour_loss: 0.6126 - val_minute_loss: 62.1947 - val_hour_categorical_accuracy: 0.7503 - val_hour_mae: 0.0555 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 4.5621\n",
            "Epoch 20/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 41.3098 - hour_loss: 0.7067 - minute_loss: 40.6031 - hour_categorical_accuracy: 0.7242 - hour_mae: 0.0590 - minute_categorical_accuracy: 1.0000 - minute_mae: 4.1900 - val_loss: 62.8515 - val_hour_loss: 0.6175 - val_minute_loss: 62.2340 - val_hour_categorical_accuracy: 0.7347 - val_hour_mae: 0.0566 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 4.4116\n",
            "Epoch 21/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 41.2555 - hour_loss: 0.6893 - minute_loss: 40.5662 - hour_categorical_accuracy: 0.7294 - hour_mae: 0.0573 - minute_categorical_accuracy: 1.0000 - minute_mae: 4.2192 - val_loss: 60.6974 - val_hour_loss: 0.6329 - val_minute_loss: 60.0645 - val_hour_categorical_accuracy: 0.7476 - val_hour_mae: 0.0558 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 4.3553\n",
            "Epoch 22/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 37.4502 - hour_loss: 0.6374 - minute_loss: 36.8129 - hour_categorical_accuracy: 0.7476 - hour_mae: 0.0534 - minute_categorical_accuracy: 1.0000 - minute_mae: 4.0254 - val_loss: 53.6232 - val_hour_loss: 0.5442 - val_minute_loss: 53.0790 - val_hour_categorical_accuracy: 0.7809 - val_hour_mae: 0.0472 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 4.0338\n",
            "Epoch 23/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 33.7441 - hour_loss: 0.6145 - minute_loss: 33.1296 - hour_categorical_accuracy: 0.7598 - hour_mae: 0.0507 - minute_categorical_accuracy: 1.0000 - minute_mae: 3.8736 - val_loss: 50.7565 - val_hour_loss: 0.5233 - val_minute_loss: 50.2332 - val_hour_categorical_accuracy: 0.7920 - val_hour_mae: 0.0489 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 3.8921\n",
            "Epoch 24/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 30.4332 - hour_loss: 0.6202 - minute_loss: 29.8130 - hour_categorical_accuracy: 0.7646 - hour_mae: 0.0505 - minute_categorical_accuracy: 1.0000 - minute_mae: 3.6778 - val_loss: 76.6756 - val_hour_loss: 0.6168 - val_minute_loss: 76.0587 - val_hour_categorical_accuracy: 0.7632 - val_hour_mae: 0.0483 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 4.7443\n",
            "Epoch 25/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 31.7596 - hour_loss: 0.5853 - minute_loss: 31.1743 - hour_categorical_accuracy: 0.7741 - hour_mae: 0.0481 - minute_categorical_accuracy: 1.0000 - minute_mae: 3.6642 - val_loss: 53.9761 - val_hour_loss: 0.5179 - val_minute_loss: 53.4582 - val_hour_categorical_accuracy: 0.7896 - val_hour_mae: 0.0465 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 4.2061\n",
            "Epoch 26/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 32.0661 - hour_loss: 0.5841 - minute_loss: 31.4819 - hour_categorical_accuracy: 0.7760 - hour_mae: 0.0476 - minute_categorical_accuracy: 1.0000 - minute_mae: 3.7526 - val_loss: 57.5806 - val_hour_loss: 0.5160 - val_minute_loss: 57.0646 - val_hour_categorical_accuracy: 0.7868 - val_hour_mae: 0.0475 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 3.9634\n",
            "Epoch 27/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 28.4874 - hour_loss: 0.5415 - minute_loss: 27.9458 - hour_categorical_accuracy: 0.7864 - hour_mae: 0.0454 - minute_categorical_accuracy: 1.0000 - minute_mae: 3.5086 - val_loss: 50.8097 - val_hour_loss: 0.4712 - val_minute_loss: 50.3385 - val_hour_categorical_accuracy: 0.8115 - val_hour_mae: 0.0435 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 3.7279\n",
            "Epoch 28/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 23.5677 - hour_loss: 0.5134 - minute_loss: 23.0543 - hour_categorical_accuracy: 0.8052 - hour_mae: 0.0431 - minute_categorical_accuracy: 1.0000 - minute_mae: 3.2805 - val_loss: 49.4609 - val_hour_loss: 0.4612 - val_minute_loss: 48.9997 - val_hour_categorical_accuracy: 0.8181 - val_hour_mae: 0.0407 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 3.5107\n",
            "Epoch 29/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 21.0914 - hour_loss: 0.4846 - minute_loss: 20.6069 - hour_categorical_accuracy: 0.8165 - hour_mae: 0.0403 - minute_categorical_accuracy: 1.0000 - minute_mae: 3.1065 - val_loss: 48.0801 - val_hour_loss: 0.5418 - val_minute_loss: 47.5383 - val_hour_categorical_accuracy: 0.7920 - val_hour_mae: 0.0433 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 3.5459\n",
            "Epoch 30/30\n",
            "360/360 [==============================] - 3s 9ms/step - loss: 26.4721 - hour_loss: 0.5771 - minute_loss: 25.8949 - hour_categorical_accuracy: 0.7846 - hour_mae: 0.0447 - minute_categorical_accuracy: 1.0000 - minute_mae: 3.3903 - val_loss: 50.6551 - val_hour_loss: 0.4531 - val_minute_loss: 50.2020 - val_hour_categorical_accuracy: 0.8205 - val_hour_mae: 0.0392 - val_minute_categorical_accuracy: 1.0000 - val_minute_mae: 3.4294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9pAvt6cV4Lk"
      },
      "source": [
        "[y_test_hour, y_test_minute] = get_y(y_test)\n",
        "\n",
        "[y_pred_hour, y_pred_minute] = model.predict(X_test)\n",
        "\n",
        "y_test_hour = np.argmax(y_test_hour, axis=1)\n",
        "\n",
        "y_pred_hour = np.argmax(y_pred_hour, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQA0-AgSWAmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d60b47b-b470-45f6-f49f-227fd4fa3dd3"
      },
      "source": [
        "print(classification_report(y_test_hour, y_pred_hour))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.82      0.83       288\n",
            "           1       0.80      0.74      0.77       308\n",
            "           2       0.78      0.86      0.82       322\n",
            "           3       0.83      0.78      0.81       279\n",
            "           4       0.79      0.83      0.81       309\n",
            "           5       0.77      0.86      0.81       279\n",
            "           6       0.88      0.73      0.80       313\n",
            "           7       0.83      0.76      0.79       305\n",
            "           8       0.73      0.92      0.82       320\n",
            "           9       0.88      0.85      0.86       291\n",
            "          10       0.81      0.88      0.84       281\n",
            "          11       0.93      0.77      0.85       305\n",
            "\n",
            "    accuracy                           0.82      3600\n",
            "   macro avg       0.82      0.82      0.82      3600\n",
            "weighted avg       0.82      0.82      0.82      3600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAGpnzSNWEqX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5efaaf3-da7b-4616-d5b6-8f896ce731c9"
      },
      "source": [
        "print(f\"MAE: {mean_absolute_error(y_pred_minute, y_test_minute)}\")\n",
        "print(f\"Adjusted MAE: {adjusted_mae_numpy(y_pred_minute, y_test_minute, 60)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 3.4772036364509\n",
            "Adjusted MAE: 3.089523071994384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o53GlaOSoYd"
      },
      "source": [
        "print(f\"MAE: {mean_absolute_error(y_pred_hour, y_test_hour)}\")\n",
        "print(f\"Adjusted MAE: {adjusted_mae_numpy(y_pred_hour.reshape(-1, 1), y_test_hour.reshape(-1, 1), 12)}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}